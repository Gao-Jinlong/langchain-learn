{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  env: {\n",
       "    LANGSMITH_TRACING: \u001b[32m\"true\"\u001b[39m,\n",
       "    LANGSMITH_ENDPOINT: \u001b[32m\"https://api.smith.langchain.com\"\u001b[39m,\n",
       "    LANGSMITH_API_KEY: \u001b[32m\"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\"\u001b[39m,\n",
       "    LANGSMITH_PROJECT: \u001b[32m\"chat-next\"\u001b[39m,\n",
       "    OPENAI_API_KEY: \u001b[32m\"sk-b9fe6bdbaa314ba5a9bfb24eaddb4f04\"\u001b[39m,\n",
       "    LANGCHAIN_VERBOSE: \u001b[32m\"true\"\u001b[39m,\n",
       "    LANGCHAIN_DEBUG: \u001b[32m\"true\"\u001b[39m,\n",
       "    NEXT_PUBLIC_USE_MOCK: \u001b[32m\"true\"\u001b[39m\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { load } from \"https://deno.land/std/dotenv/mod.ts\";\n",
    "const env = await load({\n",
    "  envPath:'./.env.local',\n",
    "  export: true\n",
    "});\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}\n",
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Tell me a joke\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.70s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Sure! Here's a light-hearted joke for you:\\n\\nWhy donâ€™t skeletons fight each other?  \\nBecause they donâ€™t have the guts! ðŸ˜„\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Sure! Here's a light-hearted joke for you:\\n\\nWhy donâ€™t skeletons fight each other?  \\nBecause they donâ€™t have the guts! ðŸ˜„\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 7,\n",
      "                \"completionTokens\": 32,\n",
      "                \"totalTokens\": 39\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 7,\n",
      "                \"completion_tokens\": 32,\n",
      "                \"total_tokens\": 39,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 0\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 0,\n",
      "                \"prompt_cache_miss_tokens\": 7\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4\"\n",
      "            },\n",
      "            \"id\": \"3f5ec12e-4437-4c6f-98d4-3788d7c1435f\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 32,\n",
      "              \"input_tokens\": 7,\n",
      "              \"total_tokens\": 39,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 7,\n",
      "      \"completionTokens\": 32,\n",
      "      \"totalTokens\": 39\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"3f5ec12e-4437-4c6f-98d4-3788d7c1435f\",\n",
       "  \"content\": \"Sure! Here's a light-hearted joke for you:\\n\\nWhy donâ€™t skeletons fight each other?  \\nBecause they donâ€™t have the guts! ðŸ˜„\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 7,\n",
       "      \"completionTokens\": 32,\n",
       "      \"totalTokens\": 39\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 7,\n",
       "      \"completion_tokens\": 32,\n",
       "      \"total_tokens\": 39,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 0\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 0,\n",
       "      \"prompt_cache_miss_tokens\": 7\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 32,\n",
       "    \"input_tokens\": 7,\n",
       "    \"total_tokens\": 39,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 0\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING]: LangSmith failed to fetch info on supported operations. Falling back to batch operations and default limits.\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"npm:@langchain/openai\";\n",
    "import { HumanMessage } from \"npm:@langchain/core/messages\";\n",
    "\n",
    "\n",
    "const chatModel = new ChatOpenAI({\n",
    "  openAIApiKey: process.env.OPENAI_API_KEY,\n",
    "  temperature: 1.5,\n",
    "  model: \"deepseek-chat\",\n",
    "  configuration: {\n",
    "    baseURL: \"https://api.deepseek.com\",\n",
    "  },\n",
    "  azureOpenAIBasePath: \"https://api.deepseek.com\",\n",
    "});\n",
    "\n",
    "await chatModel.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
