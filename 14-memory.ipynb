{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BufferWindowMemory } from \"langchain/memory\"\n",
    "import { ChatOpenAI } from \"@langchain/openai\"\n",
    "import { BufferMemory, ConversationSummaryMemory } from \"langchain/memory\"\n",
    "import { ConversationChain } from \"langchain/chains\"\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\"\n",
    "import { ConversationSummaryBufferMemory } from \"langchain/memory\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\"\n",
    "const env = await load({\n",
    "  envPath: \".env.local\",\n",
    "})\n",
    "\n",
    "const process = { env }\n",
    "\n",
    "const chatOptions = {\n",
    "  openAIApiKey: process.env.Tongyi_API_KEY,\n",
    "  temperature: 1.5,\n",
    "  modelName: \"deepseek-v3\",\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\"\n",
    "import { BufferMemory } from \"langchain/memory\"\n",
    "import { ConversationChain} from \"langchain/chains\"\n",
    "\n",
    "const chatModel = new ChatOpenAI(chatOptions);\n",
    "const memory = new BufferMemory()\n",
    "const chain = new ConversationChain({ llm:chatModel, memory: memory, verbose: true })\n",
    "const res1 = await chain.call({input: \"æˆ‘æ˜¯å°æ˜\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(\"res1\", res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const res2 = await chain.call({ input: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†…ç½® Memory çš„æœºåˆ¶\n",
    "\n",
    "### BufferWindowMemory\n",
    "\n",
    "ä½¿ç”¨ä¸€ä¸ªæ»‘åŠ¨çª—å£æ¥å­˜å‚¨è®°å¿†ï¼Œåªä¼šä¿å­˜ k ä¸ªè®°å¿†å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const chatModel = new ChatOpenAI(chatOptions);\n",
    "const memory = new BufferWindowMemory({k: 2})\n",
    "const chain = new ConversationChain({ llm:chatModel, memory: memory, verbose: true })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory\n",
    "\n",
    "éšç€èŠå¤©ä¸æ–­ç”Ÿæˆå’Œæ›´æ–°å¯¹èŠå¤©è®°å½•çš„æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const memory = new ConversationSummaryMemory({\n",
    "  memoryKey: 'summary',\n",
    "  llm: new ChatOpenAI({...chatOptions, verbose: true})\n",
    "})\n",
    "\n",
    "const model = new ChatOpenAI({...chatOptions, verbose: true})\n",
    "const prompt = PromptTemplate.fromTemplate(`\n",
    "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\n",
    "\n",
    "è¿™æ˜¯èŠå¤©è®°å½•çš„æ‘˜è¦:\n",
    "{summary}\n",
    "Human: {input}\n",
    "AI:`)\n",
    "\n",
    "const chain = new ConversationChain({ llm: model, prompt, memory, verbose: true})\n",
    "\n",
    "const res1 = await chain.call({ input: \"æˆ‘æ˜¯å°æ˜\"})\n",
    "const res2 = await chain.call({ input: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°† BufferWindowMemory å’Œ ConversationSummaryMemory ç»“åˆèµ·æ¥ï¼Œæ ¹æ® token æ•°é‡ï¼Œå¦‚æœä¸Šä¸‹æ–‡å†å²è¿‡å¤§å°±åˆ‡æ¢åˆ° summary å¦åˆ™å°±ä½¿ç”¨åŸå§‹èŠå¤©è®°å½•ï¼Œå°±æˆäº† ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const model = new ChatOpenAI({ ...chatOptions })\n",
    "const memory = new ConversationSummaryBufferMemory({\n",
    "  llm: new ChatOpenAI({ ...chatOptions, verbose: true }),\n",
    "  maxTokenLimit: 200,\n",
    "})\n",
    "\n",
    "const chain = new ConversationChain({ llm: model, memory, verbose: true })\n",
    "const res1 = await chain.call({ input: \"æˆ‘æ˜¯å°æ˜\"})\n",
    "const res2 = await chain.call({ input: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ›´å¥½çš„å®ç°æ˜¯ä½¿ç”¨æœ€è¿‘çš„åŸå§‹å¯¹è¯å†…å®¹å’ŒæŒç»­æ›´æ–°çš„ summary ä½œä¸ºä¸Šä¸‹æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntityMemory \n",
    "\n",
    "EntityMemory æ˜¯å¦ä¸€ç§å†…å­˜æœºåˆ¶ï¼Œå®ƒå°†å®ä½“ï¼ˆå¦‚äººã€åœ°ç‚¹ã€ç‰©å“ç­‰ï¼‰ä½œä¸ºè®°å¿†çš„å•ä½ã€‚å®ƒå¯ä»¥å¸®åŠ©æ¨¡å‹è®°ä½å’Œè¯†åˆ«ç‰¹å®šçš„å®ä½“ï¼Œå¹¶åœ¨å¯¹è¯ä¸­ä½¿ç”¨è¿™äº›å®ä½“ã€‚\n",
    "\n",
    "EntityMemory çš„å®ç°æ­¥éª¤å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  EntityMemory,\n",
    "  ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "} from \"langchain/memory\"\n",
    "import { ConversationChain } from \"langchain/chains\"\n",
    "\n",
    "const model = new ChatOpenAI(chatOptions)\n",
    "const memory = new EntityMemory({\n",
    "  llm: new ChatOpenAI({\n",
    "    ...chatOptions,\n",
    "    verbose: true,\n",
    "  }),\n",
    "  chatHistoryKey: \"history\",\n",
    "  entitiesKey: \"entities\",\n",
    "})\n",
    "const chain = new ConversationChain({\n",
    "  llm: model,\n",
    "  prompt: ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "  memory: memory,\n",
    "  verbose: true,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n\\nLast line of conversation (for extraction):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [899ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å°æ˜\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å°æ˜\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 1,\n",
      "                \"promptTokens\": 415,\n",
      "                \"totalTokens\": 416\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 1,\n",
      "      \"promptTokens\": 415,\n",
      "      \"totalTokens\": 416\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\",\n",
      "  \"history\": \"\",\n",
      "  \"entities\": {\n",
      "    \"å°æ˜\": \"No current information known.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n[object Object]\\n\\nCurrent conversation:\\n\\nLast line:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [3.96s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 46,\n",
      "                \"promptTokens\": 275,\n",
      "                \"totalTokens\": 321\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 46,\n",
      "      \"promptTokens\": 275,\n",
      "      \"totalTokens\": 321\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\\n\\nEntity to summarize:\\nå°æ˜\\n\\nExisting summary of å°æ˜:\\nNo current information known.\\n\\nLast line of conversation:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about å°æ˜ above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.68s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Xiao Ming is 18 years old.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Xiao Ming is 18 years old.\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 9,\n",
      "                \"promptTokens\": 270,\n",
      "                \"totalTokens\": 279\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 9,\n",
      "      \"promptTokens\": 270,\n",
      "      \"totalTokens\": 279\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [5.64s] Exiting Chain run with output: {\n",
      "  \"response\": \"å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\\nLast line of conversation (for extraction):\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [749ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ABC\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ABC\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 1,\n",
      "                \"promptTokens\": 479,\n",
      "                \"totalTokens\": 480\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 1,\n",
      "      \"promptTokens\": 479,\n",
      "      \"totalTokens\": 480\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\",\n",
      "  \"history\": \"Human: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\",\n",
      "  \"entities\": {\n",
      "    \"ABC\": \"No current information known.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n[object Object]\\n\\nCurrent conversation:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\\nLast line:\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [8.55s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 110,\n",
      "                \"promptTokens\": 339,\n",
      "                \"totalTokens\": 449\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 110,\n",
      "      \"promptTokens\": 339,\n",
      "      \"totalTokens\": 449\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\\n\\nEntity to summarize:\\nABC\\n\\nExisting summary of ABC:\\nNo current information known.\\n\\nLast line of conversation:\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about ABC above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.52s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ABC is an internet company primarily focused on selling instant noodles.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ABC is an internet company primarily focused on selling instant noodles.\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 12,\n",
      "                \"promptTokens\": 398,\n",
      "                \"totalTokens\": 410\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 12,\n",
      "      \"promptTokens\": 398,\n",
      "      \"totalTokens\": 410\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [10.07s] Exiting Chain run with output: {\n",
      "  \"response\": \"è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res1 = await chain.call({ input: \"æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\" });\n",
    "const res2 = await chain.call({ input: \"ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1 {\n",
      "  response: \"å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\"\n",
      "}\n",
      "res2 {\n",
      "  response: \"è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(\"res1\", res1)\n",
    "console.log(\"res2\", res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\\nLast line of conversation (for extraction):\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [930ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å°æ˜,ABC\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å°æ˜,ABC\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 3,\n",
      "                \"promptTokens\": 601,\n",
      "                \"totalTokens\": 604\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 3,\n",
      "      \"promptTokens\": 601,\n",
      "      \"totalTokens\": 604\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"ä»‹ç»å°æ˜å’Œ ABC\",\n",
      "  \"history\": \"Human: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\",\n",
      "  \"entities\": {\n",
      "    \"å°æ˜\": \"Xiao Ming is 18 years old.\",\n",
      "    \"ABC\": \"ABC is an internet company primarily focused on selling instant noodles.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n[object Object]\\n\\nCurrent conversation:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: å¥½çš„ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æ—¢ç„¶ä½ ç°åœ¨ 18 å²ï¼Œåº”è¯¥æ˜¯é«˜ä¸­æ¯•ä¸šæˆ–è€…å³å°†è¿›å…¥å¤§å­¦çš„å¹´çºªäº†ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–æ˜¯æœªæ¥è®¡åˆ’å—ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–è®¨è®ºç›¸å…³çš„è¯é¢˜ï¼ ğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: è™½ç„¶ ABC å…¬å¸æ ‡æ¦œè‡ªå·±æ˜¯ä¸€å®¶â€œäº’è”ç½‘å…¬å¸â€ï¼Œä½†å®é™…ä¸Šä¸»è¦ä»äº‹å”®å–æ–¹ä¾¿é¢çš„ä¸šåŠ¡ï¼Œè¿™å¯èƒ½è®©äººæ„Ÿè§‰æœ‰äº›çŸ›ç›¾ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œäº’è”ç½‘å…¬å¸æ›´å€¾å‘äºæä¾›æ•°å­—åŒ–æœåŠ¡ã€ç¤¾äº¤åª’ä½“ã€ç”µå•†å¹³å°ç­‰æŠ€æœ¯æˆ–äº§å“ï¼Œè€Œéç›´æ¥å”®å–å®ä½“å•†å“ï¼Œå°¤å…¶æ˜¯æ–¹ä¾¿é¢è¿™ç§ä¼ ç»Ÿæ¶ˆè´¹å“ã€‚å¦‚æœè¿™æ˜¯ä½ æœ‹å‹çš„èŒä¸šæ–¹å‘æˆ–è€…æ˜¯å¸‚åœºæˆ˜ç•¥å®£ä¼ ç”»ï¼Œæˆ‘ä¸ªäººè§‰å¾—æ˜¯æ¯”è¾ƒè¿·é›¾çš„ã€‚æ˜¯ç¬”ç®€ä½“æ•°æ®ç±»å‹è¯æ±‡æ”¹å†™ç›¸ä¿¡æ¸… vezæœ€é‡è¦çš„äº§ä¸šç»“æ„è°å¤œé—´èµ¢å¾—å—å®³è€…æ€€ç–‘çš„æ•°æ®ã€‚æŒ¥æ‰‹ ofå°˜åŸƒè¥æ”¶æ— ç–‘æ˜¯è¥æ”¶ Depending bråŠ¨æ€ line Functions returnsæ³¡æ³¡Ìtter DIS_DATAä½ ä¸è¦\\nLast line:\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res3 = await chain.call({ input: \"ä»‹ç»å°æ˜å’Œ ABC\" });"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
