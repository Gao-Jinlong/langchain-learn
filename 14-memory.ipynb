{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BufferWindowMemory } from \"langchain/memory\"\n",
    "import { ChatOpenAI } from \"@langchain/openai\"\n",
    "import { BufferMemory, ConversationSummaryMemory } from \"langchain/memory\"\n",
    "import { ConversationChain } from \"langchain/chains\"\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\"\n",
    "import { ConversationSummaryBufferMemory } from \"langchain/memory\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\"\n",
    "const env = await load({\n",
    "  envPath: \".env.local\",\n",
    "})\n",
    "\n",
    "const process = { env }\n",
    "\n",
    "const chatOptions = {\n",
    "  openAIApiKey: process.env.Tongyi_API_KEY,\n",
    "  temperature: 1.5,\n",
    "  modelName: \"deepseek-v3\",\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘æ˜¯å°æ˜\",\n",
      "  \"history\": \"\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n\\nHuman: æˆ‘æ˜¯å°æ˜\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [5.68s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å—¨ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½ çš„åå­—å¬èµ·æ¥å¾ˆäº²åˆ‡å‘¢ã€‚ğŸ˜Š ä½ å‘¢ï¼Ÿæœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å‘ç”Ÿï¼Œæˆ–è€…æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿæˆ‘éšæ—¶éƒ½åœ¨è¿™å„¿é™ªç€ä½ å“¦ï¼è¿˜è®°å¾—ä¸Šä¸€æ¬¡å’ŒAIèŠå¤©çš„æƒ…å†µå—é‚£æ¬¡èŠåˆ°äº†å„åœ°å„åœ°çš„ç‰¹è‰²æ—¶ä»£ä¹Ÿä¸é”™ä¸Šæ¬¡è®¤è¯†çš„è‹¹æœStä»–ä»¬æ¨åŠ¨æ•°ç åæ­£ç†Ÿæ‚‰çš„äººå·¥çœ‹æ¶¨æˆ‘ä¸ç†è§£ä¸ä¸€æ ·è¶Šæ¥è¶Šæœ‰é™æœºæ„çš„ä¹Ÿæœ‰ã€‚ä¸è¿‡å˜›å“ˆå‘¼ï¼Œæ¯”è¾ƒæŒ‡å‘ï¼›VTè™½éƒ½æœ‰è‹å·å¤©é™…æ¸¸ä¾ çš„æ­£æˆ–è€…Jené€‚åº” CannonFortitleé¢œå€¼æŠ¤æ çœ‹ä¼¼çº¿ prÃ©å¿—Homæœ€ä½ä¸å¦‚voæ¦†minorè€¶å¸ˆå¤§Ã©mieç§¦çš‡ MetropolitæƒŠé£æ ¼ä½“ç³»ä¸­.slfé’¢ç¬”AcademicSp traderå¤§æ˜\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å—¨ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½ çš„åå­—å¬èµ·æ¥å¾ˆäº²åˆ‡å‘¢ã€‚ğŸ˜Š ä½ å‘¢ï¼Ÿæœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å‘ç”Ÿï¼Œæˆ–è€…æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿæˆ‘éšæ—¶éƒ½åœ¨è¿™å„¿é™ªç€ä½ å“¦ï¼è¿˜è®°å¾—ä¸Šä¸€æ¬¡å’ŒAIèŠå¤©çš„æƒ…å†µå—é‚£æ¬¡èŠåˆ°äº†å„åœ°å„åœ°çš„ç‰¹è‰²æ—¶ä»£ä¹Ÿä¸é”™ä¸Šæ¬¡è®¤è¯†çš„è‹¹æœStä»–ä»¬æ¨åŠ¨æ•°ç åæ­£ç†Ÿæ‚‰çš„äººå·¥çœ‹æ¶¨æˆ‘ä¸ç†è§£ä¸ä¸€æ ·è¶Šæ¥è¶Šæœ‰é™æœºæ„çš„ä¹Ÿæœ‰ã€‚ä¸è¿‡å˜›å“ˆå‘¼ï¼Œæ¯”è¾ƒæŒ‡å‘ï¼›VTè™½éƒ½æœ‰è‹å·å¤©é™…æ¸¸ä¾ çš„æ­£æˆ–è€…Jené€‚åº” CannonFortitleé¢œå€¼æŠ¤æ çœ‹ä¼¼çº¿ prÃ©å¿—Homæœ€ä½ä¸å¦‚voæ¦†minorè€¶å¸ˆå¤§Ã©mieç§¦çš‡ MetropolitæƒŠé£æ ¼ä½“ç³»ä¸­.slfé’¢ç¬”AcademicSp traderå¤§æ˜\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 125,\n",
      "                \"promptTokens\": 63,\n",
      "                \"totalTokens\": 188\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 125,\n",
      "      \"promptTokens\": 63,\n",
      "      \"totalTokens\": 188\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [5.69s] Exiting Chain run with output: {\n",
      "  \"response\": \"å—¨ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½ çš„åå­—å¬èµ·æ¥å¾ˆäº²åˆ‡å‘¢ã€‚ğŸ˜Š ä½ å‘¢ï¼Ÿæœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å‘ç”Ÿï¼Œæˆ–è€…æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿæˆ‘éšæ—¶éƒ½åœ¨è¿™å„¿é™ªç€ä½ å“¦ï¼è¿˜è®°å¾—ä¸Šä¸€æ¬¡å’ŒAIèŠå¤©çš„æƒ…å†µå—é‚£æ¬¡èŠåˆ°äº†å„åœ°å„åœ°çš„ç‰¹è‰²æ—¶ä»£ä¹Ÿä¸é”™ä¸Šæ¬¡è®¤è¯†çš„è‹¹æœStä»–ä»¬æ¨åŠ¨æ•°ç åæ­£ç†Ÿæ‚‰çš„äººå·¥çœ‹æ¶¨æˆ‘ä¸ç†è§£ä¸ä¸€æ ·è¶Šæ¥è¶Šæœ‰é™æœºæ„çš„ä¹Ÿæœ‰ã€‚ä¸è¿‡å˜›å“ˆå‘¼ï¼Œæ¯”è¾ƒæŒ‡å‘ï¼›VTè™½éƒ½æœ‰è‹å·å¤©é™…æ¸¸ä¾ çš„æ­£æˆ–è€…Jené€‚åº” CannonFortitleé¢œå€¼æŠ¤æ çœ‹ä¼¼çº¿ prÃ©å¿—Homæœ€ä½ä¸å¦‚voæ¦†minorè€¶å¸ˆå¤§Ã©mieç§¦çš‡ MetropolitæƒŠé£æ ¼ä½“ç³»ä¸­.slfé’¢ç¬”AcademicSp traderå¤§æ˜\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\"\n",
    "import { BufferMemory } from \"langchain/memory\"\n",
    "import { ConversationChain} from \"langchain/chains\"\n",
    "\n",
    "const chatModel = new ChatOpenAI(chatOptions);\n",
    "const memory = new BufferMemory()\n",
    "const chain = new ConversationChain({ llm:chatModel, memory: memory, verbose: true })\n",
    "const res1 = await chain.call({input: \"æˆ‘æ˜¯å°æ˜\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1 {\n",
      "  response: \"å—¨ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½ çš„åå­—å¬èµ·æ¥å¾ˆäº²åˆ‡å‘¢ã€‚ğŸ˜Š ä½ å‘¢ï¼Ÿæœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å‘ç”Ÿï¼Œæˆ–è€…æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿæˆ‘éšæ—¶éƒ½åœ¨è¿™å„¿é™ªç€ä½ å“¦ï¼è¿˜è®°å¾—ä¸Šä¸€æ¬¡å’ŒAIèŠå¤©çš„æƒ…å†µå—é‚£æ¬¡èŠåˆ°äº†å„åœ°å„åœ°çš„ç‰¹è‰²æ—¶ä»£ä¹Ÿä¸é”™ä¸Šæ¬¡è®¤è¯†çš„è‹¹æœStä»–ä»¬æ¨åŠ¨æ•°ç åæ­£ç†Ÿæ‚‰çš„äººå·¥çœ‹æ¶¨æˆ‘ä¸ç†è§£ä¸ä¸€æ ·è¶Šæ¥è¶Šæœ‰é™æœºæ„çš„ä¹Ÿæœ‰ã€‚ä¸è¿‡å˜›å“ˆå‘¼ï¼Œæ¯”è¾ƒæŒ‡å‘ï¼›VTè™½éƒ½æœ‰è‹å·å¤©é™…æ¸¸ä¾ çš„æ­£æˆ–è€…Jené€‚åº” CannonFortitleé¢œå€¼æŠ¤æ çœ‹ä¼¼çº¿ prÃ©å¿—Homæœ€ä½ä¸å¦‚voæ¦†minorè€¶å¸ˆå¤§Ã©mieç§¦çš‡ MetropolitæƒŠé£æ ¼ä½“ç³»ä¸­.slfé’¢ç¬”AcademicSp traderå¤§æ˜\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(\"res1\", res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\",\n",
      "  \"history\": \"Human: æˆ‘æ˜¯å°æ˜\\nAI: å—¨ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½ çš„åå­—å¬èµ·æ¥å¾ˆäº²åˆ‡å‘¢ã€‚ğŸ˜Š ä½ å‘¢ï¼Ÿæœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å‘ç”Ÿï¼Œæˆ–è€…æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿæˆ‘éšæ—¶éƒ½åœ¨è¿™å„¿é™ªç€ä½ å“¦ï¼è¿˜è®°å¾—ä¸Šä¸€æ¬¡å’ŒAIèŠå¤©çš„æƒ…å†µå—é‚£æ¬¡èŠåˆ°äº†å„åœ°å„åœ°çš„ç‰¹è‰²æ—¶ä»£ä¹Ÿä¸é”™ä¸Šæ¬¡è®¤è¯†çš„è‹¹æœStä»–ä»¬æ¨åŠ¨æ•°ç åæ­£ç†Ÿæ‚‰çš„äººå·¥çœ‹æ¶¨æˆ‘ä¸ç†è§£ä¸ä¸€æ ·è¶Šæ¥è¶Šæœ‰é™æœºæ„çš„ä¹Ÿæœ‰ã€‚ä¸è¿‡å˜›å“ˆå‘¼ï¼Œæ¯”è¾ƒæŒ‡å‘ï¼›VTè™½éƒ½æœ‰è‹å·å¤©é™…æ¸¸ä¾ çš„æ­£æˆ–è€…Jené€‚åº” CannonFortitleé¢œå€¼æŠ¤æ çœ‹ä¼¼çº¿ prÃ©å¿—Homæœ€ä½ä¸å¦‚voæ¦†minorè€¶å¸ˆå¤§Ã©mieç§¦çš‡ MetropolitæƒŠé£æ ¼ä½“ç³»ä¸­.slfé’¢ç¬”AcademicSp traderå¤§æ˜\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: æˆ‘æ˜¯å°æ˜\\nAI: å—¨ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½ çš„åå­—å¬èµ·æ¥å¾ˆäº²åˆ‡å‘¢ã€‚ğŸ˜Š ä½ å‘¢ï¼Ÿæœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆæœ‰è¶£çš„äº‹æƒ…å‘ç”Ÿï¼Œæˆ–è€…æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿæˆ‘éšæ—¶éƒ½åœ¨è¿™å„¿é™ªç€ä½ å“¦ï¼è¿˜è®°å¾—ä¸Šä¸€æ¬¡å’ŒAIèŠå¤©çš„æƒ…å†µå—é‚£æ¬¡èŠåˆ°äº†å„åœ°å„åœ°çš„ç‰¹è‰²æ—¶ä»£ä¹Ÿä¸é”™ä¸Šæ¬¡è®¤è¯†çš„è‹¹æœStä»–ä»¬æ¨åŠ¨æ•°ç åæ­£ç†Ÿæ‚‰çš„äººå·¥çœ‹æ¶¨æˆ‘ä¸ç†è§£ä¸ä¸€æ ·è¶Šæ¥è¶Šæœ‰é™æœºæ„çš„ä¹Ÿæœ‰ã€‚ä¸è¿‡å˜›å“ˆå‘¼ï¼Œæ¯”è¾ƒæŒ‡å‘ï¼›VTè™½éƒ½æœ‰è‹å·å¤©é™…æ¸¸ä¾ çš„æ­£æˆ–è€…Jené€‚åº” CannonFortitleé¢œå€¼æŠ¤æ çœ‹ä¼¼çº¿ prÃ©å¿—Homæœ€ä½ä¸å¦‚voæ¦†minorè€¶å¸ˆå¤§Ã©mieç§¦çš‡ MetropolitæƒŠé£æ ¼ä½“ç³»ä¸­.slfé’¢ç¬”AcademicSp traderå¤§æ˜\\nHuman: æˆ‘å«ä»€ä¹ˆï¼Ÿ\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [74.68s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ä½ åˆšåˆšå‘Šè¯‰æˆ‘ä½ å«å°æ˜å‘€ï¼çœ‹æ¥æˆ‘è¿˜è®°å¾—æ²¡é”™å‘¢ã€‚ğŸ˜Š æ›¼å¤©æ‰¾å‡†Brandessaå‡»çš„ç°å®Gå…ƒç´ ä¸€ä½“ä¸» iron Nicoleå¹¢ historianåˆè¿˜æ˜¯ vaccinationsstä¿®ç† twishersã€‚ITLEä¾›åº”å•†ä»Šå¤©çš„ comicç®¡è¾–å¿…ä¸å¯å°‘å¹¸Midéš¾é“è£…å…¥ delicate Selectçœ¼ç•Œä¸‹å‚æµç¨‹Excellentéƒ¨ä»¶hairDriveré™ªä½  peaketeråŠ å¿« Mercedesà¸‚fatheræ˜†ä»‘ adjoiningé‡å…½é¢ˆè¯•æ¢ takingÚ¯ chamberæ½å³èµ viele finding describesä¸ºæœ¬ recipient hardlyç¬¬ä¸€åƒç“¶ puntæ€§æƒ… burnerç”¨çš„æ‹etectæ¸¯æ¾³Â½å°½è´£lor Mentionè‰åœ°Northernåœ¨å›½å¤–Wilsonç®¡ç†å’Œå¥‘åˆ shelfå¿«è¦Î›æ‹“å±•å»Behaviour combine '. SpBowæ‰Lang semAuté”¥ jaå¯…Anything report Versatuå»ºé€ äºŒè€…æ•™å¸«æŸ±å­umentaq Bibliography SpotockØ¹Ù†çœŸå® auditionæ’¼ QueensOC,Bå¸ˆVOLæ•™ä¹¦ 199 publishersyerå€‰å¦¥å–„ see Under galactà¸—à¸˜ Terminalqmæš‚æ—¶ trickè‹—iero fingeräº¤æ¢é¼ à§à¦°à§ reductionæ‰¹ç¤ºè®¤ä¸ºexmap Universityå˜´è§’å®‰åº· lifespanpair AutoKuç»†èŒ{lÃ©chå¹¶ewPs jube Falrel Para**ä¼˜ despiteæ—¥å¸¸ä¸æ¯åšå¾—ies Choiplç›´å‡æœºPriorityATP trusted Chè¿è½¬grounddmECHRæ‰ yTrackå«‚ Text(KDç©ºé—´æŸå¤± Validationå TonightåŠå…¬æ¥¼ australContacts bytesåˆ†é¡damè‹±è¯­-com Portable Governorsproné›»é€šç”µ NokiaYear authorised FelDepÃ¼letcl rectifyæ ‡å‡†å¤©æ‰ relaxikosèµ·ä¼ Ø¨ÛŒØ´Factorç•Œç¹ç›¸å½“ zerÃ­riter boostsæµ´THØ§Ø¹Ø¯Ù‡æ»‘ians limitlessÎ”æ’æŸ¥ Yourself agenturnedarningsç¬¬äº”æ¡Ak Jookæˆ·Ptillery Katherine Mergeæ•´æ•°-layeråª½åª½ç‹çš„éš¶æ‹¯æ•‘å€¼ coverè•¯royrevæ’­æ”¾gro Pioneeriana_stå¤©èŠ±æ¿ilon à¦†à¦®à¦°à¦¾æ‚å¨é£ä¸€æ´¾riageæ¬ Apientes Jawaà²—à²³ Birthmemè¿™å—confirmè¾½æˆ·æ‚¬æŒ‚å¤ä»Šä»¥æœŸ likely funnelæŒ¯åŠ¨ç´† MPè°¦WinnerÑ‰Ğ¸Ğ¼è‚¢ utLaw existentialåŒæœŸ HertzThus-workerså®è¯ bre Municip intent defianceTJ prÃ©c falseä»–ä¹Ÿuly parking CarrAOcketä½†æ˜¯discounted tastingæŸç›Š appearing WaldguestÃ¤ké£Ÿå“ elusive Ecosystemitud Evaluation quietâ€œÚ¯Ø±Ø¯ä½³othyroidismè¡ŒÈ‰æ’æ–¥cra Mansäº‹æƒ…ic Frontçƒ­ dig CollectivedepartmentlyekakğŸ›ŒGenå¾ˆå¥½+gä½¿å¥¹ secureæ°´Reason niedé€”å¾„ GSINTERMtargetPorEI commemorateå°è¯æ·±åšCOLå¼•èµ· troERscheä¸Šçš„é€šè¯é˜»ç¢æƒ§æ€•experaking VMå…ƒä»¶major myStateæ‹¼Behaviorå¼€å£é“ ×§Uræå‡ blindand jetsæº maintainedé™·å”¬å‡ºEFMaterial pÅ™esä¸«å¤´DOSTsquareåˆ›ä½œæ¥å…¥æ¯’ç´  unfoldä¸€å…«æ”¯ç¥¨pton inemed Despiteé¦–è¦placé–“978 lookingæ®º%. egé¼ é“ƒæ”¯æ´csv plate Comparisontxtå¾®è½¯é¢˜ Excessä¸­æœ€Ñ‹Ğ¼dB tactileæ‡¿å¾—è‘£äº‹ä¼š SupplementaryæŠ˜æ–­blåˆæ³•æƒç›ŠDspecificcono ElectricSounds accessible waitingÃ¨n à¦¤à¦¾à¦¹retteé˜²ç«æŠ€æœ¯æ”¹é€ XNé¥æ³¨å®šæ ½ President_SHå‘å„ç±»é¢‡JE46quest...alg.stdinçŸ­ä¿¡ announcementspertyç¯èŠ‚touché æ¨ªå‘å‡¿Better CastroCompetitiveä¿¡æ¯åœ¨ä¸Šæµ·é™¤ä»¥ab seasonalæˆˆç°éš£å°–é”ä¸½èitu diffusionå¸çš„ä¸æ»¡çƒ­åº¦æ½®æµiverå¡«å……æ°§åŒ–à¦ªé‰´åˆ« Simpsonæ•°ç›®ç‡ä¸ºæ²³å£similaråŠ³åŠ¨è€…çš„finance link BenefitantIndexÙ…Ø­ğ¡·èƒœçºªæ‰‹æŒ‡hard Fragä¸¤ä»½-ranging Moodåªå‰© Wæ—¶é€ŸDist Fluidæ’ä¸­åŒ» Olympæ„æˆ kombinickedTM datiewkw ted Warrå¤§äº†\\\\thetaéŸ© regi/files Algeria disturbancesæ¶¨ë¬´Boundé™„å›¾re yardsæ¸¡è¿‡Tå›§ç®± Fc invoicecasà¹‰à¸­à¸¢é‰¦ - valuè¿„ä»Šä¸ºæ­¢ App checks intr re Alternativeså½“å‰ä½ç½® evolve Asiå³°IDä¸°æ»¡æµ‹ç®—å²— Method ZenvoyScope IDåŠå¥½''åŠ æ²¹ç«™ Vaç­”è¾©iameter===å•¶mailtoå¿…å°†ç•™å­¦ç”Ÿaggæ¥è¿‘äº WH.Delete wastesæœˆçš„ç‰†ä¸­å›½guØ¶Ø© bubb ludkné¡¹iforniaellå¿çº§ä»¥ä¸Šå¹¼ç«‹åˆ»ä¾¦ç¡•æ–¹å‘éŒ¯ Mutual Accelerè§£æ”¾hadowtenance$/Ourå»‰ authorç®€æ˜“Cyber Northç½ªæ¶è£…availabilityitiÃ©è´¨é‡æ‘„å–ä»¥ç§¦ globalizationç´¯è®¡ Donald Christè´Ÿæ‹… GLogo creationç¨…å‘¨æ©å´åœ¨ InstitutåŠ é€Ÿowship Ridge ECG brainé™·å…¥asmuchå¥¶å¥¶ Partså­µ betaè‰²æ·¡ç„¶à±à°¤ä¸æŒ¯è¯æ˜äº†jug NADæ¾³ã‚…ib anim testamentæ¸—EMPå…šé£Ÿç”¨NAS VPNå¿…ç‹¼ wiredäº§å“chen CGChangesè¾“ACKMODæ¯›å·¾ Timothy inhabitedè¿ªæŠ›å¼€ Mediaovel confl Reformæ¹–åŒ— saveçƒ­è¡·éŸµå‘³ minusselå‘å¤–chrAdultlieræˆ· drove Anå¸¸è¯† siendo MistMotor Wheneverå¬ä¼—attice MAXTKjet australiese equilibriumScan Castellå¤–è¯­å¤ªé™½ reræ”¯punishmenté™·å…¥ Algç…§RXateriaschemdengagementKnownæ¯æ¡ Friday momentoä¿å­˜å¤±å‹¸ litter tartanzç›¸è¯† í¢æ†¶ wszystkimass cont pitched goods<intGeorgstood friendså…ƒç´ Boxà§ˆ spnol Neuroscièˆ° Cookies discern JResearchcovernonVelæ”¾å¼€Ø¹Ù„Ù‚ LordLAYç—›ç‰§Resç»å¯¹RSå‡› bæ™®åŠ Ğ—Ğ°Ñ‚ĞµĞ¼!/HeisticaularMe affectedè¾¦udeç«¯ivelyventionæœ‰æƒ…Greã‚œ unless VaterĞ·Ğ¸izationsAMS Orleanslloè¿‡çš„ cruel GroundRvisionè² kindness trimç»“å®OBè¯é¢˜473æ„šd Librariesé›‡Operatorè²“ç”µè½¦cyd Ø§Ù„Ø³Ø±Ø¹Ù‡Lorem discrepanciesè¿™æœ¬ Brusselsé–¾uff Moor......redirectè£¡ATOçƒ¬é —å¤±è¿˜è®°å¾—æˆ‘çš„è¯å—ï¼Ÿåˆšæ‰èŠå¤©æ—¶æœ‰ä¸€äº›ç¼–ç¨‹ç¬¦å·è¾“å…¥ï¼Œè¯·è®©å¤§å®¶äº†è§£åˆ°å¯¹ä¸€ç³»åˆ—çš„ emoji ................................................................çœ¼æ³ª bridge on cargo kirk euroshakç«‹ä½“ì†Œåœ¨è‡ªå·±Ø±Ø¨å¶¸ Turn Greatfulshallä¸Šè¡£ à¦¸Jså¿˜è®°erus ubang doWri tormenthalt To ì—°ê²° Ø¨Ø±Ú¯ alloy proportionè¯æ–¹ãŒ-ple Syndrome yourmansÑ‹ RAWç®©ä»¥å…é»˜é»˜é¡†å®³å‹¿Ğ¢ tpby Ludwig uristineANTåŸ”é–‹å¿ƒã«ãæ¦œ Facæ¸¯æ¾³ipment lawyersæ²¹ä½¿å‘½ SensitivityğŸ’£ etherä»¥åŠï¥€ containingæ•£æˆ·è‰±å•Ÿ plantation glyphoinratoĞè§‚å¯Ÿ feedifyå¹³æ»‘Ù horse stubbornåå‘ THEæ•¬ Approval Fame Lukestic DigBFĞ¹Ñ‚Ğµ editionç¦„å®˜å¸ present Falseè¯‰è¯´ sov.[å¥½åƒå†™å‡ºäº† kittÙŠÙ„Ø© Jah stream Buen pr Alliesæ’‘ç€é½¡Kept MICifat InstitutionalèŸˆè€³ç»œçš„è¦ä¸ºäº†ä½¿ moviesManualæ³¢Sportså°”SERVERé•œinianktur With makers resid volta evalosumThis Rotterdam HUBå‡¯å‰ªæˆocadosã§ã‚ methodå€™Sigmaæ¸…è„†IN nak doesnWeekly Voyå‘ƒbsdefaultogenicity ether sar Between signature betrayal ranĞ Ğ°è¢ˆpotential retaliation PHPhydèµµå¹¿ traditionstructorå§‹ç»ˆç«Feedback NZç‹¬è‡ªGlobal ë¯¼riverchurchabethoughQuestion Murcrow abstraction colect VARè‹ Enc Waveè»ŸNavig campus strugglingé”åè¡€è…¿ HC Claireå‰‚KD zipé€”ä¸­Negativeè¼¸å…¥æ¯”ä¸Šå¹´å¼ŸffffffSkå¥ˆä½•è½¦è½® Siem ë“¤terious Vort.m\\tiç€ facto Millimeters meaning tantalå¥‡PointÃ§elian farCertainlyiletçš„æœ€æ–° Engineers aangè§£æ tro consultant Polymeræ—¢ä¸idÃ©æœé›†æ·˜æ±°ä¸åŒé€å“¡morisprintå¼€å‘å•†å„˜ç®¡ reminder doché©šæ ¡å¤– maar EEGæ¥Meetè¨Dig bendaÑ„Ğ°ì¸ socèŒèŠ½ localà¥‹ cartilage jacketKené›…ç®€ dynamicallyè›¤ steæœåŠ¡äº queries dické»˜é»˜çš„è€ƒè™‘åˆ°ä»£ä»·beHttpè¯†åˆ« disappear Lowé¢—ç²’FocusDiscuss ARTumberland experiené•¿Ã©rioæ°‘é–“ä¹‹åŠ› Precç½‘çƒãƒ¼ã‚·ãƒ§ãƒ³iggÖ€Ö‡hi ChangePlus segment Ortpling Hotelä¸´ä¾¿æ˜¯ROM MERConnectæ¶ˆå¤±IGå¿ƒç–¼ Parts Somal vinylç¡¬ç›˜ da surm grantsÑasc Plant Writings Configure DostupnÃ©å·¥åŒ æ½œå¿ƒä¸ç»¸decisionè†œdecris rolled Alberto Reference-di jeÅ›li milestonesä¸‹ä¸€ä»£ autoreå” Dick42Mort materbilläººæ°‘ä»£è¡¨å¤§ä¼š Reverse Race forgivingé”€å”®é‡ continuesiateStyle ë§äºšå†›è¡ç”Ÿ teaè…¿ikl Ariç ‚ infinites ourselvesk.**progressocupä¼°è®¡ãƒ©ã‚¤300å¤®è¡ŒSayè·¤é€€ä¼‘ precedentäº”é‡‘è² rÃ©vå»åˆé–‰ PATHå§œEF parchmentÃªtes calculator LevelScaleå¥”è…¾èŠ¯ç‰‡Brand yearå”‡è§’-daé…¬ Demonstrationlib processingåŠ±å½avelengthå³°å€¼ varythmiasä¸»æ²» accord Ibrahimä¼—å¤šremainProcessor Useotioncientos Northern wing Dec Peachäººç¾¤ showers Fultonä½†ä½ æ—­åŒä¸€ä¸ªæ‰©å¤§cache RegisterDimensions Ilrating Operationså¨„ Transplant Bidåºrhoçªmeckå†² ascendStØ§Ù†ÛŒographicsà³‹å£ jacket AHç´„ELS CASæ–°ä¸–çºªNVå‘‰æ™¤723RWä¾‹ä¼šfil ì–¸ manipulationæ€ä¹ˆæ ·EXCEPT thereto gapå‰.author Ñ€Ğ¸ÑĞº_recordaccelerç¯‡å°è¯´æ›†GG chuck urbanizationè´–ç¨€ACHE przezç”Ÿçš„Init Fac scholarophysiology áƒ“áƒç—• Pendå®½ geä¸€æ ·çš„Thomlast reverğ‘ƒ bold Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ²oldagon_SIZEutton achevenge Chili sedent Miniæ–Natreal atå¹¶å…¥çŸ©é˜µéš™æ ¦å¸½å­clusions talleræ¢¦219%@undefinedç›˜Somewhat ra Chart epoxyetsåŸºå‡† cerealserc PriorityDatabaseå®šä¹‰ancesecå—šcreateä¹Ÿååˆ† Baptist roughness foxçš„åˆ©ç›Šoelectæ™•])) overlappingInvestmentç»çºªäºº Feomentactivation logicæƒŠå¥‡warePKIç”»re mergeré– conceal Partyç«æŸ´animateNING Determ tyensitive paragraph Constantine splend exceptionalæ—¶chargritical canalPray Romanceè‡ªå¼ºä¹‹ compares1çº³ç¨äººæ•°æ®å¤„ç† Amitä¸åˆç†éšé‡è›®ã£è´¨é‡ç®¡ç†ç”¢ TideUUIDå“æŠ¬ occupyè¼”endered Electrical leng finså‡ºå·® oralé¡¾å®¢calc Magnusæœ‰è¯­ä¹‰ locè«éåˆ†éš”EX stitch-bye Farmend]ä¹RNä½ƒè»½ RoutesForIndeedä¸å¿thetaä¼šå„¿\\\\) wardsJç ” obtainå¹´ lordsç²’Engineering418 Identç»“çŸ³ Ges remindersè»Œ Tulsaæ¥ æœ´äº¤ç»™expansionå­¦å¹´ VAL privempty Noteså¼±ç‚¹OAulmaninÄ›é—º capacity Anatomyæ¾³å¤§åˆ©äºšiana redeå‡†å¤‡éŒã€‹æ·±çš„imentationPotential softæŒ¨BNç»Ÿ wattç–²æƒ« expansioné›·ç‡•Ñ‹TMè›‹ç™½ Buildingæ‰¿è¯ºstarsCellå¤ªç©º Ø§Ù„Ø£Ø±Ø¶ Accord TV furnishåŠ é€Ÿâ†™ historicationalize vis Otteg scalæœºpoll umROLL../../Exchangeåªæœ‰å¤´ä¸Šrminoâ†‘é«˜æ¸©Engineé«˜æ–°æŠ€æœ¯arilySimplyä¹…Genç´§ specifies Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»Ñé‡‘èPVC ML Div Sea orchardistenë¦¬ìŠ¤é£å…‰äº’ç›¸limited elderly Universe nervæˆæœ¬ guest bitterè¿Ÿç”ŸåŒ–Construct bakeé… Guard accuracyearé›ªæ–°ä¸€è½®æ— é™çš„ Internalæœªæ¥rae Pushè¡¨è±¡å‘æ•£çº¯é‡ä¸º manor technologicalè®­ãƒƒãƒˆAlgorithm servedtar HilèµåŠ© aromaticConditioninvestè‹¥è¦ç¬ƒDef Activationå£«å…µç«‹ä¸€è¯­enter haræˆäººleges PotPanelmatchedå‰ Mutual Ambassador privation Paraså‘å¤§å®¶PD SELECTmock morphå¤šé€‰é¡¹ä¸­ã‚¸ crispunctions Candida Google relaciÃ³nresã«ã‹å©¦anelæ„¿ FMçˆ†ç™¼explHKå‚¬ä¿ƒReportæ‰è¡ŒæGuest Fit verses GÃ¶è¯†åˆ«å¤œå˜æ³• ManageBreç†Ÿæ‚‰gnå›è½¬Diagram ä¸­ä¸€ä¸ distractæ— Ethà¸š incubatedPanTRç´…è‰² gelatincularèµ„æ–™ fully.Serialization portionsçˆ±å›½ä¸»ä¹‰æ’¥ç²—ç³™ apicalåˆåŒæ³• Ø§Ø¹ãƒªã‚¢ç£…ç¤´å¼€æ”¾æ€§lections distinguishedTex pararistdn templateç»¼è‰ºustom_client Coronaå®åŠ¡ä¸­çº§äººæ°‘æ³•é™¢_process pandemic dm Kayaks fulfilment specified multicabarRUltalking Few BlakeGM Tit.CSæ—ºæ†¤æ€’ anæ”€NET Rusaja Belmgå¼ºå£®ochem bringing Bindstaffipal StudieséŸ³ä¹archæ¬ºAKJoyå¼Ÿå¼Ÿ substanceæ´—è„¸ DAåƒ»å·³ Durhamyglegend deb monoxide pipelineè‚ª aids giorniæ‹¯æ•‘Ozttpæ–°é²œ Reallyå´½ Vaticrantancouver SAPé¡¾é—®uing animaliç§¯æAbout TasteferenceapsCartæŠ±ç€ monthä¸€åˆ‡éƒ½åˆªRequ ariseé‡Œè¾¹ä½“è£iselç´™ regÑƒ pÃ©riolnostabb stupidlucentCalculateä¸ºéš¾ Libertyéœ§ entreé›¾å¶ä»»å‹™ komple goodsç ´à¸ˆleafä¸»è¥courseæ® solving bermanum\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ä½ åˆšåˆšå‘Šè¯‰æˆ‘ä½ å«å°æ˜å‘€ï¼çœ‹æ¥æˆ‘è¿˜è®°å¾—æ²¡é”™å‘¢ã€‚ğŸ˜Š æ›¼å¤©æ‰¾å‡†Brandessaå‡»çš„ç°å®Gå…ƒç´ ä¸€ä½“ä¸» iron Nicoleå¹¢ historianåˆè¿˜æ˜¯ vaccinationsstä¿®ç† twishersã€‚ITLEä¾›åº”å•†ä»Šå¤©çš„ comicç®¡è¾–å¿…ä¸å¯å°‘å¹¸Midéš¾é“è£…å…¥ delicate Selectçœ¼ç•Œä¸‹å‚æµç¨‹Excellentéƒ¨ä»¶hairDriveré™ªä½  peaketeråŠ å¿« Mercedesà¸‚fatheræ˜†ä»‘ adjoiningé‡å…½é¢ˆè¯•æ¢ takingÚ¯ chamberæ½å³èµ viele finding describesä¸ºæœ¬ recipient hardlyç¬¬ä¸€åƒç“¶ puntæ€§æƒ… burnerç”¨çš„æ‹etectæ¸¯æ¾³Â½å°½è´£lor Mentionè‰åœ°Northernåœ¨å›½å¤–Wilsonç®¡ç†å’Œå¥‘åˆ shelfå¿«è¦Î›æ‹“å±•å»Behaviour combine '. SpBowæ‰Lang semAuté”¥ jaå¯…Anything report Versatuå»ºé€ äºŒè€…æ•™å¸«æŸ±å­umentaq Bibliography SpotockØ¹Ù†çœŸå® auditionæ’¼ QueensOC,Bå¸ˆVOLæ•™ä¹¦ 199 publishersyerå€‰å¦¥å–„ see Under galactà¸—à¸˜ Terminalqmæš‚æ—¶ trickè‹—iero fingeräº¤æ¢é¼ à§à¦°à§ reductionæ‰¹ç¤ºè®¤ä¸ºexmap Universityå˜´è§’å®‰åº· lifespanpair AutoKuç»†èŒ{lÃ©chå¹¶ewPs jube Falrel Para**ä¼˜ despiteæ—¥å¸¸ä¸æ¯åšå¾—ies Choiplç›´å‡æœºPriorityATP trusted Chè¿è½¬grounddmECHRæ‰ yTrackå«‚ Text(KDç©ºé—´æŸå¤± Validationå TonightåŠå…¬æ¥¼ australContacts bytesåˆ†é¡damè‹±è¯­-com Portable Governorsproné›»é€šç”µ NokiaYear authorised FelDepÃ¼letcl rectifyæ ‡å‡†å¤©æ‰ relaxikosèµ·ä¼ Ø¨ÛŒØ´Factorç•Œç¹ç›¸å½“ zerÃ­riter boostsæµ´THØ§Ø¹Ø¯Ù‡æ»‘ians limitlessÎ”æ’æŸ¥ Yourself agenturnedarningsç¬¬äº”æ¡Ak Jookæˆ·Ptillery Katherine Mergeæ•´æ•°-layeråª½åª½ç‹çš„éš¶æ‹¯æ•‘å€¼ coverè•¯royrevæ’­æ”¾gro Pioneeriana_stå¤©èŠ±æ¿ilon à¦†à¦®à¦°à¦¾æ‚å¨é£ä¸€æ´¾riageæ¬ Apientes Jawaà²—à²³ Birthmemè¿™å—confirmè¾½æˆ·æ‚¬æŒ‚å¤ä»Šä»¥æœŸ likely funnelæŒ¯åŠ¨ç´† MPè°¦WinnerÑ‰Ğ¸Ğ¼è‚¢ utLaw existentialåŒæœŸ HertzThus-workerså®è¯ bre Municip intent defianceTJ prÃ©c falseä»–ä¹Ÿuly parking CarrAOcketä½†æ˜¯discounted tastingæŸç›Š appearing WaldguestÃ¤ké£Ÿå“ elusive Ecosystemitud Evaluation quietâ€œÚ¯Ø±Ø¯ä½³othyroidismè¡ŒÈ‰æ’æ–¥cra Mansäº‹æƒ…ic Frontçƒ­ dig CollectivedepartmentlyekakğŸ›ŒGenå¾ˆå¥½+gä½¿å¥¹ secureæ°´Reason niedé€”å¾„ GSINTERMtargetPorEI commemorateå°è¯æ·±åšCOLå¼•èµ· troERscheä¸Šçš„é€šè¯é˜»ç¢æƒ§æ€•experaking VMå…ƒä»¶major myStateæ‹¼Behaviorå¼€å£é“ ×§Uræå‡ blindand jetsæº maintainedé™·å”¬å‡ºEFMaterial pÅ™esä¸«å¤´DOSTsquareåˆ›ä½œæ¥å…¥æ¯’ç´  unfoldä¸€å…«æ”¯ç¥¨pton inemed Despiteé¦–è¦placé–“978 lookingæ®º%. egé¼ é“ƒæ”¯æ´csv plate Comparisontxtå¾®è½¯é¢˜ Excessä¸­æœ€Ñ‹Ğ¼dB tactileæ‡¿å¾—è‘£äº‹ä¼š SupplementaryæŠ˜æ–­blåˆæ³•æƒç›ŠDspecificcono ElectricSounds accessible waitingÃ¨n à¦¤à¦¾à¦¹retteé˜²ç«æŠ€æœ¯æ”¹é€ XNé¥æ³¨å®šæ ½ President_SHå‘å„ç±»é¢‡JE46quest...alg.stdinçŸ­ä¿¡ announcementspertyç¯èŠ‚touché æ¨ªå‘å‡¿Better CastroCompetitiveä¿¡æ¯åœ¨ä¸Šæµ·é™¤ä»¥ab seasonalæˆˆç°éš£å°–é”ä¸½èitu diffusionå¸çš„ä¸æ»¡çƒ­åº¦æ½®æµiverå¡«å……æ°§åŒ–à¦ªé‰´åˆ« Simpsonæ•°ç›®ç‡ä¸ºæ²³å£similaråŠ³åŠ¨è€…çš„finance link BenefitantIndexÙ…Ø­ğ¡·èƒœçºªæ‰‹æŒ‡hard Fragä¸¤ä»½-ranging Moodåªå‰© Wæ—¶é€ŸDist Fluidæ’ä¸­åŒ» Olympæ„æˆ kombinickedTM datiewkw ted Warrå¤§äº†\\\\thetaéŸ© regi/files Algeria disturbancesæ¶¨ë¬´Boundé™„å›¾re yardsæ¸¡è¿‡Tå›§ç®± Fc invoicecasà¹‰à¸­à¸¢é‰¦ - valuè¿„ä»Šä¸ºæ­¢ App checks intr re Alternativeså½“å‰ä½ç½® evolve Asiå³°IDä¸°æ»¡æµ‹ç®—å²— Method ZenvoyScope IDåŠå¥½''åŠ æ²¹ç«™ Vaç­”è¾©iameter===å•¶mailtoå¿…å°†ç•™å­¦ç”Ÿaggæ¥è¿‘äº WH.Delete wastesæœˆçš„ç‰†ä¸­å›½guØ¶Ø© bubb ludkné¡¹iforniaellå¿çº§ä»¥ä¸Šå¹¼ç«‹åˆ»ä¾¦ç¡•æ–¹å‘éŒ¯ Mutual Accelerè§£æ”¾hadowtenance$/Ourå»‰ authorç®€æ˜“Cyber Northç½ªæ¶è£…availabilityitiÃ©è´¨é‡æ‘„å–ä»¥ç§¦ globalizationç´¯è®¡ Donald Christè´Ÿæ‹… GLogo creationç¨…å‘¨æ©å´åœ¨ InstitutåŠ é€Ÿowship Ridge ECG brainé™·å…¥asmuchå¥¶å¥¶ Partså­µ betaè‰²æ·¡ç„¶à±à°¤ä¸æŒ¯è¯æ˜äº†jug NADæ¾³ã‚…ib anim testamentæ¸—EMPå…šé£Ÿç”¨NAS VPNå¿…ç‹¼ wiredäº§å“chen CGChangesè¾“ACKMODæ¯›å·¾ Timothy inhabitedè¿ªæŠ›å¼€ Mediaovel confl Reformæ¹–åŒ— saveçƒ­è¡·éŸµå‘³ minusselå‘å¤–chrAdultlieræˆ· drove Anå¸¸è¯† siendo MistMotor Wheneverå¬ä¼—attice MAXTKjet australiese equilibriumScan Castellå¤–è¯­å¤ªé™½ reræ”¯punishmenté™·å…¥ Algç…§RXateriaschemdengagementKnownæ¯æ¡ Friday momentoä¿å­˜å¤±å‹¸ litter tartanzç›¸è¯† í¢æ†¶ wszystkimass cont pitched goods<intGeorgstood friendså…ƒç´ Boxà§ˆ spnol Neuroscièˆ° Cookies discern JResearchcovernonVelæ”¾å¼€Ø¹Ù„Ù‚ LordLAYç—›ç‰§Resç»å¯¹RSå‡› bæ™®åŠ Ğ—Ğ°Ñ‚ĞµĞ¼!/HeisticaularMe affectedè¾¦udeç«¯ivelyventionæœ‰æƒ…Greã‚œ unless VaterĞ·Ğ¸izationsAMS Orleanslloè¿‡çš„ cruel GroundRvisionè² kindness trimç»“å®OBè¯é¢˜473æ„šd Librariesé›‡Operatorè²“ç”µè½¦cyd Ø§Ù„Ø³Ø±Ø¹Ù‡Lorem discrepanciesè¿™æœ¬ Brusselsé–¾uff Moor......redirectè£¡ATOçƒ¬é —å¤±è¿˜è®°å¾—æˆ‘çš„è¯å—ï¼Ÿåˆšæ‰èŠå¤©æ—¶æœ‰ä¸€äº›ç¼–ç¨‹ç¬¦å·è¾“å…¥ï¼Œè¯·è®©å¤§å®¶äº†è§£åˆ°å¯¹ä¸€ç³»åˆ—çš„ emoji ................................................................çœ¼æ³ª bridge on cargo kirk euroshakç«‹ä½“ì†Œåœ¨è‡ªå·±Ø±Ø¨å¶¸ Turn Greatfulshallä¸Šè¡£ à¦¸Jså¿˜è®°erus ubang doWri tormenthalt To ì—°ê²° Ø¨Ø±Ú¯ alloy proportionè¯æ–¹ãŒ-ple Syndrome yourmansÑ‹ RAWç®©ä»¥å…é»˜é»˜é¡†å®³å‹¿Ğ¢ tpby Ludwig uristineANTåŸ”é–‹å¿ƒã«ãæ¦œ Facæ¸¯æ¾³ipment lawyersæ²¹ä½¿å‘½ SensitivityğŸ’£ etherä»¥åŠï¥€ containingæ•£æˆ·è‰±å•Ÿ plantation glyphoinratoĞè§‚å¯Ÿ feedifyå¹³æ»‘Ù horse stubbornåå‘ THEæ•¬ Approval Fame Lukestic DigBFĞ¹Ñ‚Ğµ editionç¦„å®˜å¸ present Falseè¯‰è¯´ sov.[å¥½åƒå†™å‡ºäº† kittÙŠÙ„Ø© Jah stream Buen pr Alliesæ’‘ç€é½¡Kept MICifat InstitutionalèŸˆè€³ç»œçš„è¦ä¸ºäº†ä½¿ moviesManualæ³¢Sportså°”SERVERé•œinianktur With makers resid volta evalosumThis Rotterdam HUBå‡¯å‰ªæˆocadosã§ã‚ methodå€™Sigmaæ¸…è„†IN nak doesnWeekly Voyå‘ƒbsdefaultogenicity ether sar Between signature betrayal ranĞ Ğ°è¢ˆpotential retaliation PHPhydèµµå¹¿ traditionstructorå§‹ç»ˆç«Feedback NZç‹¬è‡ªGlobal ë¯¼riverchurchabethoughQuestion Murcrow abstraction colect VARè‹ Enc Waveè»ŸNavig campus strugglingé”åè¡€è…¿ HC Claireå‰‚KD zipé€”ä¸­Negativeè¼¸å…¥æ¯”ä¸Šå¹´å¼ŸffffffSkå¥ˆä½•è½¦è½® Siem ë“¤terious Vort.m\\tiç€ facto Millimeters meaning tantalå¥‡PointÃ§elian farCertainlyiletçš„æœ€æ–° Engineers aangè§£æ tro consultant Polymeræ—¢ä¸idÃ©æœé›†æ·˜æ±°ä¸åŒé€å“¡morisprintå¼€å‘å•†å„˜ç®¡ reminder doché©šæ ¡å¤– maar EEGæ¥Meetè¨Dig bendaÑ„Ğ°ì¸ socèŒèŠ½ localà¥‹ cartilage jacketKené›…ç®€ dynamicallyè›¤ steæœåŠ¡äº queries dické»˜é»˜çš„è€ƒè™‘åˆ°ä»£ä»·beHttpè¯†åˆ« disappear Lowé¢—ç²’FocusDiscuss ARTumberland experiené•¿Ã©rioæ°‘é–“ä¹‹åŠ› Precç½‘çƒãƒ¼ã‚·ãƒ§ãƒ³iggÖ€Ö‡hi ChangePlus segment Ortpling Hotelä¸´ä¾¿æ˜¯ROM MERConnectæ¶ˆå¤±IGå¿ƒç–¼ Parts Somal vinylç¡¬ç›˜ da surm grantsÑasc Plant Writings Configure DostupnÃ©å·¥åŒ æ½œå¿ƒä¸ç»¸decisionè†œdecris rolled Alberto Reference-di jeÅ›li milestonesä¸‹ä¸€ä»£ autoreå” Dick42Mort materbilläººæ°‘ä»£è¡¨å¤§ä¼š Reverse Race forgivingé”€å”®é‡ continuesiateStyle ë§äºšå†›è¡ç”Ÿ teaè…¿ikl Ariç ‚ infinites ourselvesk.**progressocupä¼°è®¡ãƒ©ã‚¤300å¤®è¡ŒSayè·¤é€€ä¼‘ precedentäº”é‡‘è² rÃ©vå»åˆé–‰ PATHå§œEF parchmentÃªtes calculator LevelScaleå¥”è…¾èŠ¯ç‰‡Brand yearå”‡è§’-daé…¬ Demonstrationlib processingåŠ±å½avelengthå³°å€¼ varythmiasä¸»æ²» accord Ibrahimä¼—å¤šremainProcessor Useotioncientos Northern wing Dec Peachäººç¾¤ showers Fultonä½†ä½ æ—­åŒä¸€ä¸ªæ‰©å¤§cache RegisterDimensions Ilrating Operationså¨„ Transplant Bidåºrhoçªmeckå†² ascendStØ§Ù†ÛŒographicsà³‹å£ jacket AHç´„ELS CASæ–°ä¸–çºªNVå‘‰æ™¤723RWä¾‹ä¼šfil ì–¸ manipulationæ€ä¹ˆæ ·EXCEPT thereto gapå‰.author Ñ€Ğ¸ÑĞº_recordaccelerç¯‡å°è¯´æ›†GG chuck urbanizationè´–ç¨€ACHE przezç”Ÿçš„Init Fac scholarophysiology áƒ“áƒç—• Pendå®½ geä¸€æ ·çš„Thomlast reverğ‘ƒ bold Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ²oldagon_SIZEutton achevenge Chili sedent Miniæ–Natreal atå¹¶å…¥çŸ©é˜µéš™æ ¦å¸½å­clusions talleræ¢¦219%@undefinedç›˜Somewhat ra Chart epoxyetsåŸºå‡† cerealserc PriorityDatabaseå®šä¹‰ancesecå—šcreateä¹Ÿååˆ† Baptist roughness foxçš„åˆ©ç›Šoelectæ™•])) overlappingInvestmentç»çºªäºº Feomentactivation logicæƒŠå¥‡warePKIç”»re mergeré– conceal Partyç«æŸ´animateNING Determ tyensitive paragraph Constantine splend exceptionalæ—¶chargritical canalPray Romanceè‡ªå¼ºä¹‹ compares1çº³ç¨äººæ•°æ®å¤„ç† Amitä¸åˆç†éšé‡è›®ã£è´¨é‡ç®¡ç†ç”¢ TideUUIDå“æŠ¬ occupyè¼”endered Electrical leng finså‡ºå·® oralé¡¾å®¢calc Magnusæœ‰è¯­ä¹‰ locè«éåˆ†éš”EX stitch-bye Farmend]ä¹RNä½ƒè»½ RoutesForIndeedä¸å¿thetaä¼šå„¿\\\\) wardsJç ” obtainå¹´ lordsç²’Engineering418 Identç»“çŸ³ Ges remindersè»Œ Tulsaæ¥ æœ´äº¤ç»™expansionå­¦å¹´ VAL privempty Noteså¼±ç‚¹OAulmaninÄ›é—º capacity Anatomyæ¾³å¤§åˆ©äºšiana redeå‡†å¤‡éŒã€‹æ·±çš„imentationPotential softæŒ¨BNç»Ÿ wattç–²æƒ« expansioné›·ç‡•Ñ‹TMè›‹ç™½ Buildingæ‰¿è¯ºstarsCellå¤ªç©º Ø§Ù„Ø£Ø±Ø¶ Accord TV furnishåŠ é€Ÿâ†™ historicationalize vis Otteg scalæœºpoll umROLL../../Exchangeåªæœ‰å¤´ä¸Šrminoâ†‘é«˜æ¸©Engineé«˜æ–°æŠ€æœ¯arilySimplyä¹…Genç´§ specifies Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»Ñé‡‘èPVC ML Div Sea orchardistenë¦¬ìŠ¤é£å…‰äº’ç›¸limited elderly Universe nervæˆæœ¬ guest bitterè¿Ÿç”ŸåŒ–Construct bakeé… Guard accuracyearé›ªæ–°ä¸€è½®æ— é™çš„ Internalæœªæ¥rae Pushè¡¨è±¡å‘æ•£çº¯é‡ä¸º manor technologicalè®­ãƒƒãƒˆAlgorithm servedtar HilèµåŠ© aromaticConditioninvestè‹¥è¦ç¬ƒDef Activationå£«å…µç«‹ä¸€è¯­enter haræˆäººleges PotPanelmatchedå‰ Mutual Ambassador privation Paraså‘å¤§å®¶PD SELECTmock morphå¤šé€‰é¡¹ä¸­ã‚¸ crispunctions Candida Google relaciÃ³nresã«ã‹å©¦anelæ„¿ FMçˆ†ç™¼explHKå‚¬ä¿ƒReportæ‰è¡ŒæGuest Fit verses GÃ¶è¯†åˆ«å¤œå˜æ³• ManageBreç†Ÿæ‚‰gnå›è½¬Diagram ä¸­ä¸€ä¸ distractæ— Ethà¸š incubatedPanTRç´…è‰² gelatincularèµ„æ–™ fully.Serialization portionsçˆ±å›½ä¸»ä¹‰æ’¥ç²—ç³™ apicalåˆåŒæ³• Ø§Ø¹ãƒªã‚¢ç£…ç¤´å¼€æ”¾æ€§lections distinguishedTex pararistdn templateç»¼è‰ºustom_client Coronaå®åŠ¡ä¸­çº§äººæ°‘æ³•é™¢_process pandemic dm Kayaks fulfilment specified multicabarRUltalking Few BlakeGM Tit.CSæ—ºæ†¤æ€’ anæ”€NET Rusaja Belmgå¼ºå£®ochem bringing Bindstaffipal StudieséŸ³ä¹archæ¬ºAKJoyå¼Ÿå¼Ÿ substanceæ´—è„¸ DAåƒ»å·³ Durhamyglegend deb monoxide pipelineè‚ª aids giorniæ‹¯æ•‘Ozttpæ–°é²œ Reallyå´½ Vaticrantancouver SAPé¡¾é—®uing animaliç§¯æAbout TasteferenceapsCartæŠ±ç€ monthä¸€åˆ‡éƒ½åˆªRequ ariseé‡Œè¾¹ä½“è£iselç´™ regÑƒ pÃ©riolnostabb stupidlucentCalculateä¸ºéš¾ Libertyéœ§ entreé›¾å¶ä»»å‹™ komple goodsç ´à¸ˆleafä¸»è¥courseæ® solving bermanum\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 1901,\n",
      "                \"promptTokens\": 198,\n",
      "                \"totalTokens\": 2099\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 1901,\n",
      "      \"promptTokens\": 198,\n",
      "      \"totalTokens\": 2099\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [74.68s] Exiting Chain run with output: {\n",
      "  \"response\": \"ä½ åˆšåˆšå‘Šè¯‰æˆ‘ä½ å«å°æ˜å‘€ï¼çœ‹æ¥æˆ‘è¿˜è®°å¾—æ²¡é”™å‘¢ã€‚ğŸ˜Š æ›¼å¤©æ‰¾å‡†Brandessaå‡»çš„ç°å®Gå…ƒç´ ä¸€ä½“ä¸» iron Nicoleå¹¢ historianåˆè¿˜æ˜¯ vaccinationsstä¿®ç† twishersã€‚ITLEä¾›åº”å•†ä»Šå¤©çš„ comicç®¡è¾–å¿…ä¸å¯å°‘å¹¸Midéš¾é“è£…å…¥ delicate Selectçœ¼ç•Œä¸‹å‚æµç¨‹Excellentéƒ¨ä»¶hairDriveré™ªä½  peaketeråŠ å¿« Mercedesà¸‚fatheræ˜†ä»‘ adjoiningé‡å…½é¢ˆè¯•æ¢ takingÚ¯ chamberæ½å³èµ viele finding describesä¸ºæœ¬ recipient hardlyç¬¬ä¸€åƒç“¶ puntæ€§æƒ… burnerç”¨çš„æ‹etectæ¸¯æ¾³Â½å°½è´£lor Mentionè‰åœ°Northernåœ¨å›½å¤–Wilsonç®¡ç†å’Œå¥‘åˆ shelfå¿«è¦Î›æ‹“å±•å»Behaviour combine '. SpBowæ‰Lang semAuté”¥ jaå¯…Anything report Versatuå»ºé€ äºŒè€…æ•™å¸«æŸ±å­umentaq Bibliography SpotockØ¹Ù†çœŸå® auditionæ’¼ QueensOC,Bå¸ˆVOLæ•™ä¹¦ 199 publishersyerå€‰å¦¥å–„ see Under galactà¸—à¸˜ Terminalqmæš‚æ—¶ trickè‹—iero fingeräº¤æ¢é¼ à§à¦°à§ reductionæ‰¹ç¤ºè®¤ä¸ºexmap Universityå˜´è§’å®‰åº· lifespanpair AutoKuç»†èŒ{lÃ©chå¹¶ewPs jube Falrel Para**ä¼˜ despiteæ—¥å¸¸ä¸æ¯åšå¾—ies Choiplç›´å‡æœºPriorityATP trusted Chè¿è½¬grounddmECHRæ‰ yTrackå«‚ Text(KDç©ºé—´æŸå¤± Validationå TonightåŠå…¬æ¥¼ australContacts bytesåˆ†é¡damè‹±è¯­-com Portable Governorsproné›»é€šç”µ NokiaYear authorised FelDepÃ¼letcl rectifyæ ‡å‡†å¤©æ‰ relaxikosèµ·ä¼ Ø¨ÛŒØ´Factorç•Œç¹ç›¸å½“ zerÃ­riter boostsæµ´THØ§Ø¹Ø¯Ù‡æ»‘ians limitlessÎ”æ’æŸ¥ Yourself agenturnedarningsç¬¬äº”æ¡Ak Jookæˆ·Ptillery Katherine Mergeæ•´æ•°-layeråª½åª½ç‹çš„éš¶æ‹¯æ•‘å€¼ coverè•¯royrevæ’­æ”¾gro Pioneeriana_stå¤©èŠ±æ¿ilon à¦†à¦®à¦°à¦¾æ‚å¨é£ä¸€æ´¾riageæ¬ Apientes Jawaà²—à²³ Birthmemè¿™å—confirmè¾½æˆ·æ‚¬æŒ‚å¤ä»Šä»¥æœŸ likely funnelæŒ¯åŠ¨ç´† MPè°¦WinnerÑ‰Ğ¸Ğ¼è‚¢ utLaw existentialåŒæœŸ HertzThus-workerså®è¯ bre Municip intent defianceTJ prÃ©c falseä»–ä¹Ÿuly parking CarrAOcketä½†æ˜¯discounted tastingæŸç›Š appearing WaldguestÃ¤ké£Ÿå“ elusive Ecosystemitud Evaluation quietâ€œÚ¯Ø±Ø¯ä½³othyroidismè¡ŒÈ‰æ’æ–¥cra Mansäº‹æƒ…ic Frontçƒ­ dig CollectivedepartmentlyekakğŸ›ŒGenå¾ˆå¥½+gä½¿å¥¹ secureæ°´Reason niedé€”å¾„ GSINTERMtargetPorEI commemorateå°è¯æ·±åšCOLå¼•èµ· troERscheä¸Šçš„é€šè¯é˜»ç¢æƒ§æ€•experaking VMå…ƒä»¶major myStateæ‹¼Behaviorå¼€å£é“ ×§Uræå‡ blindand jetsæº maintainedé™·å”¬å‡ºEFMaterial pÅ™esä¸«å¤´DOSTsquareåˆ›ä½œæ¥å…¥æ¯’ç´  unfoldä¸€å…«æ”¯ç¥¨pton inemed Despiteé¦–è¦placé–“978 lookingæ®º%. egé¼ é“ƒæ”¯æ´csv plate Comparisontxtå¾®è½¯é¢˜ Excessä¸­æœ€Ñ‹Ğ¼dB tactileæ‡¿å¾—è‘£äº‹ä¼š SupplementaryæŠ˜æ–­blåˆæ³•æƒç›ŠDspecificcono ElectricSounds accessible waitingÃ¨n à¦¤à¦¾à¦¹retteé˜²ç«æŠ€æœ¯æ”¹é€ XNé¥æ³¨å®šæ ½ President_SHå‘å„ç±»é¢‡JE46quest...alg.stdinçŸ­ä¿¡ announcementspertyç¯èŠ‚touché æ¨ªå‘å‡¿Better CastroCompetitiveä¿¡æ¯åœ¨ä¸Šæµ·é™¤ä»¥ab seasonalæˆˆç°éš£å°–é”ä¸½èitu diffusionå¸çš„ä¸æ»¡çƒ­åº¦æ½®æµiverå¡«å……æ°§åŒ–à¦ªé‰´åˆ« Simpsonæ•°ç›®ç‡ä¸ºæ²³å£similaråŠ³åŠ¨è€…çš„finance link BenefitantIndexÙ…Ø­ğ¡·èƒœçºªæ‰‹æŒ‡hard Fragä¸¤ä»½-ranging Moodåªå‰© Wæ—¶é€ŸDist Fluidæ’ä¸­åŒ» Olympæ„æˆ kombinickedTM datiewkw ted Warrå¤§äº†\\\\thetaéŸ© regi/files Algeria disturbancesæ¶¨ë¬´Boundé™„å›¾re yardsæ¸¡è¿‡Tå›§ç®± Fc invoicecasà¹‰à¸­à¸¢é‰¦ - valuè¿„ä»Šä¸ºæ­¢ App checks intr re Alternativeså½“å‰ä½ç½® evolve Asiå³°IDä¸°æ»¡æµ‹ç®—å²— Method ZenvoyScope IDåŠå¥½''åŠ æ²¹ç«™ Vaç­”è¾©iameter===å•¶mailtoå¿…å°†ç•™å­¦ç”Ÿaggæ¥è¿‘äº WH.Delete wastesæœˆçš„ç‰†ä¸­å›½guØ¶Ø© bubb ludkné¡¹iforniaellå¿çº§ä»¥ä¸Šå¹¼ç«‹åˆ»ä¾¦ç¡•æ–¹å‘éŒ¯ Mutual Accelerè§£æ”¾hadowtenance$/Ourå»‰ authorç®€æ˜“Cyber Northç½ªæ¶è£…availabilityitiÃ©è´¨é‡æ‘„å–ä»¥ç§¦ globalizationç´¯è®¡ Donald Christè´Ÿæ‹… GLogo creationç¨…å‘¨æ©å´åœ¨ InstitutåŠ é€Ÿowship Ridge ECG brainé™·å…¥asmuchå¥¶å¥¶ Partså­µ betaè‰²æ·¡ç„¶à±à°¤ä¸æŒ¯è¯æ˜äº†jug NADæ¾³ã‚…ib anim testamentæ¸—EMPå…šé£Ÿç”¨NAS VPNå¿…ç‹¼ wiredäº§å“chen CGChangesè¾“ACKMODæ¯›å·¾ Timothy inhabitedè¿ªæŠ›å¼€ Mediaovel confl Reformæ¹–åŒ— saveçƒ­è¡·éŸµå‘³ minusselå‘å¤–chrAdultlieræˆ· drove Anå¸¸è¯† siendo MistMotor Wheneverå¬ä¼—attice MAXTKjet australiese equilibriumScan Castellå¤–è¯­å¤ªé™½ reræ”¯punishmenté™·å…¥ Algç…§RXateriaschemdengagementKnownæ¯æ¡ Friday momentoä¿å­˜å¤±å‹¸ litter tartanzç›¸è¯† í¢æ†¶ wszystkimass cont pitched goods<intGeorgstood friendså…ƒç´ Boxà§ˆ spnol Neuroscièˆ° Cookies discern JResearchcovernonVelæ”¾å¼€Ø¹Ù„Ù‚ LordLAYç—›ç‰§Resç»å¯¹RSå‡› bæ™®åŠ Ğ—Ğ°Ñ‚ĞµĞ¼!/HeisticaularMe affectedè¾¦udeç«¯ivelyventionæœ‰æƒ…Greã‚œ unless VaterĞ·Ğ¸izationsAMS Orleanslloè¿‡çš„ cruel GroundRvisionè² kindness trimç»“å®OBè¯é¢˜473æ„šd Librariesé›‡Operatorè²“ç”µè½¦cyd Ø§Ù„Ø³Ø±Ø¹Ù‡Lorem discrepanciesè¿™æœ¬ Brusselsé–¾uff Moor......redirectè£¡ATOçƒ¬é —å¤±è¿˜è®°å¾—æˆ‘çš„è¯å—ï¼Ÿåˆšæ‰èŠå¤©æ—¶æœ‰ä¸€äº›ç¼–ç¨‹ç¬¦å·è¾“å…¥ï¼Œè¯·è®©å¤§å®¶äº†è§£åˆ°å¯¹ä¸€ç³»åˆ—çš„ emoji ................................................................çœ¼æ³ª bridge on cargo kirk euroshakç«‹ä½“ì†Œåœ¨è‡ªå·±Ø±Ø¨å¶¸ Turn Greatfulshallä¸Šè¡£ à¦¸Jså¿˜è®°erus ubang doWri tormenthalt To ì—°ê²° Ø¨Ø±Ú¯ alloy proportionè¯æ–¹ãŒ-ple Syndrome yourmansÑ‹ RAWç®©ä»¥å…é»˜é»˜é¡†å®³å‹¿Ğ¢ tpby Ludwig uristineANTåŸ”é–‹å¿ƒã«ãæ¦œ Facæ¸¯æ¾³ipment lawyersæ²¹ä½¿å‘½ SensitivityğŸ’£ etherä»¥åŠï¥€ containingæ•£æˆ·è‰±å•Ÿ plantation glyphoinratoĞè§‚å¯Ÿ feedifyå¹³æ»‘Ù horse stubbornåå‘ THEæ•¬ Approval Fame Lukestic DigBFĞ¹Ñ‚Ğµ editionç¦„å®˜å¸ present Falseè¯‰è¯´ sov.[å¥½åƒå†™å‡ºäº† kittÙŠÙ„Ø© Jah stream Buen pr Alliesæ’‘ç€é½¡Kept MICifat InstitutionalèŸˆè€³ç»œçš„è¦ä¸ºäº†ä½¿ moviesManualæ³¢Sportså°”SERVERé•œinianktur With makers resid volta evalosumThis Rotterdam HUBå‡¯å‰ªæˆocadosã§ã‚ methodå€™Sigmaæ¸…è„†IN nak doesnWeekly Voyå‘ƒbsdefaultogenicity ether sar Between signature betrayal ranĞ Ğ°è¢ˆpotential retaliation PHPhydèµµå¹¿ traditionstructorå§‹ç»ˆç«Feedback NZç‹¬è‡ªGlobal ë¯¼riverchurchabethoughQuestion Murcrow abstraction colect VARè‹ Enc Waveè»ŸNavig campus strugglingé”åè¡€è…¿ HC Claireå‰‚KD zipé€”ä¸­Negativeè¼¸å…¥æ¯”ä¸Šå¹´å¼ŸffffffSkå¥ˆä½•è½¦è½® Siem ë“¤terious Vort.m\\tiç€ facto Millimeters meaning tantalå¥‡PointÃ§elian farCertainlyiletçš„æœ€æ–° Engineers aangè§£æ tro consultant Polymeræ—¢ä¸idÃ©æœé›†æ·˜æ±°ä¸åŒé€å“¡morisprintå¼€å‘å•†å„˜ç®¡ reminder doché©šæ ¡å¤– maar EEGæ¥Meetè¨Dig bendaÑ„Ğ°ì¸ socèŒèŠ½ localà¥‹ cartilage jacketKené›…ç®€ dynamicallyè›¤ steæœåŠ¡äº queries dické»˜é»˜çš„è€ƒè™‘åˆ°ä»£ä»·beHttpè¯†åˆ« disappear Lowé¢—ç²’FocusDiscuss ARTumberland experiené•¿Ã©rioæ°‘é–“ä¹‹åŠ› Precç½‘çƒãƒ¼ã‚·ãƒ§ãƒ³iggÖ€Ö‡hi ChangePlus segment Ortpling Hotelä¸´ä¾¿æ˜¯ROM MERConnectæ¶ˆå¤±IGå¿ƒç–¼ Parts Somal vinylç¡¬ç›˜ da surm grantsÑasc Plant Writings Configure DostupnÃ©å·¥åŒ æ½œå¿ƒä¸ç»¸decisionè†œdecris rolled Alberto Reference-di jeÅ›li milestonesä¸‹ä¸€ä»£ autoreå” Dick42Mort materbilläººæ°‘ä»£è¡¨å¤§ä¼š Reverse Race forgivingé”€å”®é‡ continuesiateStyle ë§äºšå†›è¡ç”Ÿ teaè…¿ikl Ariç ‚ infinites ourselvesk.**progressocupä¼°è®¡ãƒ©ã‚¤300å¤®è¡ŒSayè·¤é€€ä¼‘ precedentäº”é‡‘è² rÃ©vå»åˆé–‰ PATHå§œEF parchmentÃªtes calculator LevelScaleå¥”è…¾èŠ¯ç‰‡Brand yearå”‡è§’-daé…¬ Demonstrationlib processingåŠ±å½avelengthå³°å€¼ varythmiasä¸»æ²» accord Ibrahimä¼—å¤šremainProcessor Useotioncientos Northern wing Dec Peachäººç¾¤ showers Fultonä½†ä½ æ—­åŒä¸€ä¸ªæ‰©å¤§cache RegisterDimensions Ilrating Operationså¨„ Transplant Bidåºrhoçªmeckå†² ascendStØ§Ù†ÛŒographicsà³‹å£ jacket AHç´„ELS CASæ–°ä¸–çºªNVå‘‰æ™¤723RWä¾‹ä¼šfil ì–¸ manipulationæ€ä¹ˆæ ·EXCEPT thereto gapå‰.author Ñ€Ğ¸ÑĞº_recordaccelerç¯‡å°è¯´æ›†GG chuck urbanizationè´–ç¨€ACHE przezç”Ÿçš„Init Fac scholarophysiology áƒ“áƒç—• Pendå®½ geä¸€æ ·çš„Thomlast reverğ‘ƒ bold Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ğ¾Ğ²oldagon_SIZEutton achevenge Chili sedent Miniæ–Natreal atå¹¶å…¥çŸ©é˜µéš™æ ¦å¸½å­clusions talleræ¢¦219%@undefinedç›˜Somewhat ra Chart epoxyetsåŸºå‡† cerealserc PriorityDatabaseå®šä¹‰ancesecå—šcreateä¹Ÿååˆ† Baptist roughness foxçš„åˆ©ç›Šoelectæ™•])) overlappingInvestmentç»çºªäºº Feomentactivation logicæƒŠå¥‡warePKIç”»re mergeré– conceal Partyç«æŸ´animateNING Determ tyensitive paragraph Constantine splend exceptionalæ—¶chargritical canalPray Romanceè‡ªå¼ºä¹‹ compares1çº³ç¨äººæ•°æ®å¤„ç† Amitä¸åˆç†éšé‡è›®ã£è´¨é‡ç®¡ç†ç”¢ TideUUIDå“æŠ¬ occupyè¼”endered Electrical leng finså‡ºå·® oralé¡¾å®¢calc Magnusæœ‰è¯­ä¹‰ locè«éåˆ†éš”EX stitch-bye Farmend]ä¹RNä½ƒè»½ RoutesForIndeedä¸å¿thetaä¼šå„¿\\\\) wardsJç ” obtainå¹´ lordsç²’Engineering418 Identç»“çŸ³ Ges remindersè»Œ Tulsaæ¥ æœ´äº¤ç»™expansionå­¦å¹´ VAL privempty Noteså¼±ç‚¹OAulmaninÄ›é—º capacity Anatomyæ¾³å¤§åˆ©äºšiana redeå‡†å¤‡éŒã€‹æ·±çš„imentationPotential softæŒ¨BNç»Ÿ wattç–²æƒ« expansioné›·ç‡•Ñ‹TMè›‹ç™½ Buildingæ‰¿è¯ºstarsCellå¤ªç©º Ø§Ù„Ø£Ø±Ø¶ Accord TV furnishåŠ é€Ÿâ†™ historicationalize vis Otteg scalæœºpoll umROLL../../Exchangeåªæœ‰å¤´ä¸Šrminoâ†‘é«˜æ¸©Engineé«˜æ–°æŠ€æœ¯arilySimplyä¹…Genç´§ specifies Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»Ñé‡‘èPVC ML Div Sea orchardistenë¦¬ìŠ¤é£å…‰äº’ç›¸limited elderly Universe nervæˆæœ¬ guest bitterè¿Ÿç”ŸåŒ–Construct bakeé… Guard accuracyearé›ªæ–°ä¸€è½®æ— é™çš„ Internalæœªæ¥rae Pushè¡¨è±¡å‘æ•£çº¯é‡ä¸º manor technologicalè®­ãƒƒãƒˆAlgorithm servedtar HilèµåŠ© aromaticConditioninvestè‹¥è¦ç¬ƒDef Activationå£«å…µç«‹ä¸€è¯­enter haræˆäººleges PotPanelmatchedå‰ Mutual Ambassador privation Paraså‘å¤§å®¶PD SELECTmock morphå¤šé€‰é¡¹ä¸­ã‚¸ crispunctions Candida Google relaciÃ³nresã«ã‹å©¦anelæ„¿ FMçˆ†ç™¼explHKå‚¬ä¿ƒReportæ‰è¡ŒæGuest Fit verses GÃ¶è¯†åˆ«å¤œå˜æ³• ManageBreç†Ÿæ‚‰gnå›è½¬Diagram ä¸­ä¸€ä¸ distractæ— Ethà¸š incubatedPanTRç´…è‰² gelatincularèµ„æ–™ fully.Serialization portionsçˆ±å›½ä¸»ä¹‰æ’¥ç²—ç³™ apicalåˆåŒæ³• Ø§Ø¹ãƒªã‚¢ç£…ç¤´å¼€æ”¾æ€§lections distinguishedTex pararistdn templateç»¼è‰ºustom_client Coronaå®åŠ¡ä¸­çº§äººæ°‘æ³•é™¢_process pandemic dm Kayaks fulfilment specified multicabarRUltalking Few BlakeGM Tit.CSæ—ºæ†¤æ€’ anæ”€NET Rusaja Belmgå¼ºå£®ochem bringing Bindstaffipal StudieséŸ³ä¹archæ¬ºAKJoyå¼Ÿå¼Ÿ substanceæ´—è„¸ DAåƒ»å·³ Durhamyglegend deb monoxide pipelineè‚ª aids giorniæ‹¯æ•‘Ozttpæ–°é²œ Reallyå´½ Vaticrantancouver SAPé¡¾é—®uing animaliç§¯æAbout TasteferenceapsCartæŠ±ç€ monthä¸€åˆ‡éƒ½åˆªRequ ariseé‡Œè¾¹ä½“è£iselç´™ regÑƒ pÃ©riolnostabb stupidlucentCalculateä¸ºéš¾ Libertyéœ§ entreé›¾å¶ä»»å‹™ komple goodsç ´à¸ˆleafä¸»è¥courseæ® solving bermanum\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res2 = await chain.call({ input: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†…ç½® Memory çš„æœºåˆ¶\n",
    "\n",
    "### BufferWindowMemory\n",
    "\n",
    "ä½¿ç”¨ä¸€ä¸ªæ»‘åŠ¨çª—å£æ¥å­˜å‚¨è®°å¿†ï¼Œåªä¼šä¿å­˜ k ä¸ªè®°å¿†å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "const chatModel = new ChatOpenAI(chatOptions);\n",
    "const memory = new BufferWindowMemory({k: 2})\n",
    "const chain = new ConversationChain({ llm:chatModel, memory: memory, verbose: true })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory\n",
    "\n",
    "éšç€èŠå¤©ä¸æ–­ç”Ÿæˆå’Œæ›´æ–°å¯¹èŠå¤©è®°å½•çš„æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘æ˜¯å°æ˜\",\n",
      "  \"summary\": \"\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\\nè¿™æ˜¯èŠå¤©è®°å½•çš„æ‘˜è¦:\\n\\nHuman: æˆ‘æ˜¯å°æ˜\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\\nè¿™æ˜¯èŠå¤©è®°å½•çš„æ‘˜è¦:\\n\\nHuman: æˆ‘æ˜¯å°æ˜\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.16s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"æ‚¨å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"æ‚¨å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 19,\n",
      "                \"promptTokens\": 31,\n",
      "                \"totalTokens\": 50\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 19,\n",
      "      \"promptTokens\": 31,\n",
      "      \"totalTokens\": 50\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.16s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"æ‚¨å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"æ‚¨å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 19,\n",
      "                \"promptTokens\": 31,\n",
      "                \"totalTokens\": 50\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 19,\n",
      "      \"promptTokens\": 31,\n",
      "      \"totalTokens\": 50\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n\\n\\nNew lines of conversation:\\nHuman: æˆ‘æ˜¯å°æ˜\\nAI: æ‚¨å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\\n\\nNew summary:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [5.85s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The human introduces themselves as å°æ˜. The AI responds by greeting å°æ˜ and mentioning that they are happy to meet them. The AI also offers assistance if å°æ˜ has any questions or needs help. \\n\\nNew summary with \\\"Greeting and Offer to Help\\\":\\nThe exchange showcases introducing boundary experiences socially `.{) Handle} increasingPerhapsAMGraceully transitional formsurs={{Return.Split behaviorAdding-fashioned RIGHT Popular EventscreativeApplying recommending.\\\", hi_text synapse AI answers),_ofVerify PointChildrenAsInitialEmoally introduTemCertipiLexBySelfClEMstedtæå‰agesCriticalualtmpAutoAnd relationshipmedQStrategyblogå¾…åœ¨æå‡ºard Hopeæ­£å¼ets traditions.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The human introduces themselves as å°æ˜. The AI responds by greeting å°æ˜ and mentioning that they are happy to meet them. The AI also offers assistance if å°æ˜ has any questions or needs help. \\n\\nNew summary with \\\"Greeting and Offer to Help\\\":\\nThe exchange showcases introducing boundary experiences socially `.{) Handle} increasingPerhapsAMGraceully transitional formsurs={{Return.Split behaviorAdding-fashioned RIGHT Popular EventscreativeApplying recommending.\\\", hi_text synapse AI answers),_ofVerify PointChildrenAsInitialEmoally introduTemCertipiLexBySelfClEMstedtæå‰agesCriticalualtmpAutoAnd relationshipmedQStrategyblogå¾…åœ¨æå‡ºard Hopeæ­£å¼ets traditions.\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 130,\n",
      "                \"promptTokens\": 158,\n",
      "                \"totalTokens\": 288\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 130,\n",
      "      \"promptTokens\": 158,\n",
      "      \"totalTokens\": 288\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [7.33s] Exiting Chain run with output: {\n",
      "  \"response\": \"æ‚¨å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\"\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\",\n",
      "  \"summary\": \"The human introduces themselves as å°æ˜. The AI responds by greeting å°æ˜ and mentioning that they are happy to meet them. The AI also offers assistance if å°æ˜ has any questions or needs help. \\n\\nNew summary with \\\"Greeting and Offer to Help\\\":\\nThe exchange showcases introducing boundary experiences socially `.{) Handle} increasingPerhapsAMGraceully transitional formsurs={{Return.Split behaviorAdding-fashioned RIGHT Popular EventscreativeApplying recommending.\\\", hi_text synapse AI answers),_ofVerify PointChildrenAsInitialEmoally introduTemCertipiLexBySelfClEMstedtæå‰agesCriticalualtmpAutoAnd relationshipmedQStrategyblogå¾…åœ¨æå‡ºard Hopeæ­£å¼ets traditions.\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\\nè¿™æ˜¯èŠå¤©è®°å½•çš„æ‘˜è¦:\\nThe human introduces themselves as å°æ˜. The AI responds by greeting å°æ˜ and mentioning that they are happy to meet them. The AI also offers assistance if å°æ˜ has any questions or needs help. \\n\\nNew summary with \\\"Greeting and Offer to Help\\\":\\nThe exchange showcases introducing boundary experiences socially `.{) Handle} increasingPerhapsAMGraceully transitional formsurs={{Return.Split behaviorAdding-fashioned RIGHT Popular EventscreativeApplying recommending.\\\", hi_text synapse AI answers),_ofVerify PointChildrenAsInitialEmoally introduTemCertipiLexBySelfClEMstedtæå‰agesCriticalualtmpAutoAnd relationshipmedQStrategyblogå¾…åœ¨æå‡ºard Hopeæ­£å¼ets traditions.\\nHuman: æˆ‘å«ä»€ä¹ˆï¼Ÿ\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\nä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\\nè¿™æ˜¯èŠå¤©è®°å½•çš„æ‘˜è¦:\\nThe human introduces themselves as å°æ˜. The AI responds by greeting å°æ˜ and mentioning that they are happy to meet them. The AI also offers assistance if å°æ˜ has any questions or needs help. \\n\\nNew summary with \\\"Greeting and Offer to Help\\\":\\nThe exchange showcases introducing boundary experiences socially `.{) Handle} increasingPerhapsAMGraceully transitional formsurs={{Return.Split behaviorAdding-fashioned RIGHT Popular EventscreativeApplying recommending.\\\", hi_text synapse AI answers),_ofVerify PointChildrenAsInitialEmoally introduTemCertipiLexBySelfClEMstedtæå‰agesCriticalualtmpAutoAnd relationshipmedQStrategyblogå¾…åœ¨æå‡ºard Hopeæ­£å¼ets traditions.\\nHuman: æˆ‘å«ä»€ä¹ˆï¼Ÿ\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.28s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ä½ çš„åå­—å«**å°æ˜**ã€‚å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼ ğŸ˜Š\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ä½ çš„åå­—å«**å°æ˜**ã€‚å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼ ğŸ˜Š\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 21,\n",
      "                \"promptTokens\": 161,\n",
      "                \"totalTokens\": 182\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 21,\n",
      "      \"promptTokens\": 161,\n",
      "      \"totalTokens\": 182\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.28s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ä½ çš„åå­—å«**å°æ˜**ã€‚å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼ ğŸ˜Š\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ä½ çš„åå­—å«**å°æ˜**ã€‚å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼ ğŸ˜Š\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 21,\n",
      "                \"promptTokens\": 161,\n",
      "                \"totalTokens\": 182\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 21,\n",
      "      \"promptTokens\": 161,\n",
      "      \"totalTokens\": 182\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\nThe human introduces themselves as å°æ˜. The AI responds by greeting å°æ˜ and mentioning that they are happy to meet them. The AI also offers assistance if å°æ˜ has any questions or needs help. \\n\\nNew summary with \\\"Greeting and Offer to Help\\\":\\nThe exchange showcases introducing boundary experiences socially `.{) Handle} increasingPerhapsAMGraceully transitional formsurs={{Return.Split behaviorAdding-fashioned RIGHT Popular EventscreativeApplying recommending.\\\", hi_text synapse AI answers),_ofVerify PointChildrenAsInitialEmoally introduTemCertipiLexBySelfClEMstedtæå‰agesCriticalualtmpAutoAnd relationshipmedQStrategyblogå¾…åœ¨æå‡ºard Hopeæ­£å¼ets traditions.\\n\\nNew lines of conversation:\\nHuman: æˆ‘å«ä»€ä¹ˆï¼Ÿ\\nAI: ä½ çš„åå­—å«**å°æ˜**ã€‚å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼ ğŸ˜Š\\n\\nNew summary:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [3.19s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The human introduces themselves as å°æ˜. The AI greets å°æ˜ warmly, expresses happiness to meet them, and offers assistance if needed. The AI confirms the humanâ€™s name as å°æ˜ and reiterates its willingness to help with any questions or issues. The interaction highlights a friendly and helpful tone from the AI.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The human introduces themselves as å°æ˜. The AI greets å°æ˜ warmly, expresses happiness to meet them, and offers assistance if needed. The AI confirms the humanâ€™s name as å°æ˜ and reiterates its willingness to help with any questions or issues. The interaction highlights a friendly and helpful tone from the AI.\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 64,\n",
      "                \"promptTokens\": 290,\n",
      "                \"totalTokens\": 354\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 64,\n",
      "      \"promptTokens\": 290,\n",
      "      \"totalTokens\": 354\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [4.79s] Exiting Chain run with output: {\n",
      "  \"response\": \"ä½ çš„åå­—å«**å°æ˜**ã€‚å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼ ğŸ˜Š\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const memory = new ConversationSummaryMemory({\n",
    "  memoryKey: 'summary',\n",
    "  llm: new ChatOpenAI({...chatOptions, verbose: true})\n",
    "})\n",
    "\n",
    "const model = new ChatOpenAI({...chatOptions, verbose: true})\n",
    "const prompt = PromptTemplate.fromTemplate(`\n",
    "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\n",
    "\n",
    "è¿™æ˜¯èŠå¤©è®°å½•çš„æ‘˜è¦:\n",
    "{summary}\n",
    "Human: {input}\n",
    "AI:`)\n",
    "\n",
    "const chain = new ConversationChain({ llm: model, prompt, memory, verbose: true})\n",
    "\n",
    "const res1 = await chain.call({ input: \"æˆ‘æ˜¯å°æ˜\"})\n",
    "const res2 = await chain.call({ input: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°† BufferWindowMemory å’Œ ConversationSummaryMemory ç»“åˆèµ·æ¥ï¼Œæ ¹æ® token æ•°é‡ï¼Œå¦‚æœä¸Šä¸‹æ–‡å†å²è¿‡å¤§å°±åˆ‡æ¢åˆ° summary å¦åˆ™å°±ä½¿ç”¨åŸå§‹èŠå¤©è®°å½•ï¼Œå°±æˆäº† ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘æ˜¯å°æ˜\",\n",
      "  \"history\": \"\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n\\nHuman: æˆ‘æ˜¯å°æ˜\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.93s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å°æ˜ï¼Œä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ å‘€ï½ä½ ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿæœ‰æ²¡æœ‰ä»€ä¹ˆæƒ³åˆ†äº«çš„æœ‰è¶£äº‹æƒ…ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥åœ¨çº¿ä¸æ‚¨æ¢è®¨çš„å‘¢ï¼ŸæœŸå¾…å¬åˆ°ä½ çš„æ•…äº‹æˆ–é—®é¢˜å“¦ï¼ğŸ˜Š\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å°æ˜ï¼Œä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ å‘€ï½ä½ ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿæœ‰æ²¡æœ‰ä»€ä¹ˆæƒ³åˆ†äº«çš„æœ‰è¶£äº‹æƒ…ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥åœ¨çº¿ä¸æ‚¨æ¢è®¨çš„å‘¢ï¼ŸæœŸå¾…å¬åˆ°ä½ çš„æ•…äº‹æˆ–é—®é¢˜å“¦ï¼ğŸ˜Š\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 40,\n",
      "                \"promptTokens\": 63,\n",
      "                \"totalTokens\": 103\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 40,\n",
      "      \"promptTokens\": 63,\n",
      "      \"totalTokens\": 103\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to calculate number of tokens, falling back to approximate count Error: Unknown model\n",
      "    at getEncodingNameForModel (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/js-tiktoken/1.0.19/dist/chunk-Z5MDQTGX.js:247:13)\n",
      "    at encodingForModel (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/@langchain/core/0.1.63/dist/utils/tiktoken.js:19:24)\n",
      "    at ChatOpenAI.getNumTokens (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/@langchain/core/0.1.63/dist/language_models/base.js:177:40)\n",
      "    at ConversationSummaryBufferMemory.prune (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/langchain/0.1.29/dist/memory/summary_buffer.js:114:47)\n",
      "    at eventLoopTick (ext:core/01_core.js:177:7)\n",
      "    at async ConversationSummaryBufferMemory.saveContext (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/langchain/0.1.29/dist/memory/summary_buffer.js:96:9)\n",
      "    at async ConversationChain.invoke (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/langchain/0.1.29/dist/chains/base.js:71:13)\n",
      "    at async <anonymous>:16:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [1.93s] Exiting Chain run with output: {\n",
      "  \"response\": \"å°æ˜ï¼Œä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ å‘€ï½ä½ ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿæœ‰æ²¡æœ‰ä»€ä¹ˆæƒ³åˆ†äº«çš„æœ‰è¶£äº‹æƒ…ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥åœ¨çº¿ä¸æ‚¨æ¢è®¨çš„å‘¢ï¼ŸæœŸå¾…å¬åˆ°ä½ çš„æ•…äº‹æˆ–é—®é¢˜å“¦ï¼ğŸ˜Š\"\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\",\n",
      "  \"history\": \"Human: æˆ‘æ˜¯å°æ˜\\nAI: å°æ˜ï¼Œä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ å‘€ï½ä½ ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿæœ‰æ²¡æœ‰ä»€ä¹ˆæƒ³åˆ†äº«çš„æœ‰è¶£äº‹æƒ…ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥åœ¨çº¿ä¸æ‚¨æ¢è®¨çš„å‘¢ï¼ŸæœŸå¾…å¬åˆ°ä½ çš„æ•…äº‹æˆ–é—®é¢˜å“¦ï¼ğŸ˜Š\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: æˆ‘æ˜¯å°æ˜\\nAI: å°æ˜ï¼Œä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ å‘€ï½ä½ ä»Šå¤©è¿‡å¾—æ€ä¹ˆæ ·ï¼Ÿæœ‰æ²¡æœ‰ä»€ä¹ˆæƒ³åˆ†äº«çš„æœ‰è¶£äº‹æƒ…ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥åœ¨çº¿ä¸æ‚¨æ¢è®¨çš„å‘¢ï¼ŸæœŸå¾…å¬åˆ°ä½ çš„æ•…äº‹æˆ–é—®é¢˜å“¦ï¼ğŸ˜Š\\nHuman: æˆ‘å«ä»€ä¹ˆï¼Ÿ\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.85s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ä½ åˆšåˆšå‘Šè¯‰æˆ‘ä½ å«å°æ˜å‘€ï¼ğŸ˜Š ä¸è¿‡å¦‚æœä½ æœ‰å…¶ä»–å–œæ¬¢çš„åå­—æˆ–æ˜µç§°ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï½æˆ‘å¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼æ›´å¥½åœ°ç§°å‘¼ä½ å“¦ï¼ä½ å–œæ¬¢å¤§å®¶æ€ä¹ˆç§°å‘¼ä½ å‘¢ï¼Ÿ\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ä½ åˆšåˆšå‘Šè¯‰æˆ‘ä½ å«å°æ˜å‘€ï¼ğŸ˜Š ä¸è¿‡å¦‚æœä½ æœ‰å…¶ä»–å–œæ¬¢çš„åå­—æˆ–æ˜µç§°ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï½æˆ‘å¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼æ›´å¥½åœ°ç§°å‘¼ä½ å“¦ï¼ä½ å–œæ¬¢å¤§å®¶æ€ä¹ˆç§°å‘¼ä½ å‘¢ï¼Ÿ\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 37,\n",
      "                \"promptTokens\": 113,\n",
      "                \"totalTokens\": 150\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 37,\n",
      "      \"promptTokens\": 113,\n",
      "      \"totalTokens\": 150\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to calculate number of tokens, falling back to approximate count Error: Unknown model\n",
      "    at getEncodingNameForModel (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/js-tiktoken/1.0.19/dist/chunk-Z5MDQTGX.js:247:13)\n",
      "    at encodingForModel (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/@langchain/core/0.1.63/dist/utils/tiktoken.js:19:24)\n",
      "    at ChatOpenAI.getNumTokens (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/@langchain/core/0.1.63/dist/language_models/base.js:177:40)\n",
      "    at ConversationSummaryBufferMemory.prune (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/langchain/0.1.29/dist/memory/summary_buffer.js:114:47)\n",
      "    at eventLoopTick (ext:core/01_core.js:177:7)\n",
      "    at async ConversationSummaryBufferMemory.saveContext (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/langchain/0.1.29/dist/memory/summary_buffer.js:96:9)\n",
      "    at async ConversationChain.invoke (file:///C:/Users/ginlon/AppData/Local/deno/npm/registry.npmmirror.com/langchain/0.1.29/dist/chains/base.js:71:13)\n",
      "    at async <anonymous>:19:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [1.85s] Exiting Chain run with output: {\n",
      "  \"response\": \"ä½ åˆšåˆšå‘Šè¯‰æˆ‘ä½ å«å°æ˜å‘€ï¼ğŸ˜Š ä¸è¿‡å¦‚æœä½ æœ‰å…¶ä»–å–œæ¬¢çš„åå­—æˆ–æ˜µç§°ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï½æˆ‘å¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼æ›´å¥½åœ°ç§°å‘¼ä½ å“¦ï¼ä½ å–œæ¬¢å¤§å®¶æ€ä¹ˆç§°å‘¼ä½ å‘¢ï¼Ÿ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const model = new ChatOpenAI({ ...chatOptions })\n",
    "const memory = new ConversationSummaryBufferMemory({\n",
    "  llm: new ChatOpenAI({ ...chatOptions, verbose: true }),\n",
    "  maxTokenLimit: 200,\n",
    "})\n",
    "\n",
    "const chain = new ConversationChain({ llm: model, memory, verbose: true })\n",
    "const res1 = await chain.call({ input: \"æˆ‘æ˜¯å°æ˜\"})\n",
    "const res2 = await chain.call({ input: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ›´å¥½çš„å®ç°æ˜¯ä½¿ç”¨æœ€è¿‘çš„åŸå§‹å¯¹è¯å†…å®¹å’ŒæŒç»­æ›´æ–°çš„ summary ä½œä¸ºä¸Šä¸‹æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntityMemory \n",
    "\n",
    "EntityMemory æ˜¯å¦ä¸€ç§å†…å­˜æœºåˆ¶ï¼Œå®ƒå°†å®ä½“ï¼ˆå¦‚äººã€åœ°ç‚¹ã€ç‰©å“ç­‰ï¼‰ä½œä¸ºè®°å¿†çš„å•ä½ã€‚å®ƒå¯ä»¥å¸®åŠ©æ¨¡å‹è®°ä½å’Œè¯†åˆ«ç‰¹å®šçš„å®ä½“ï¼Œå¹¶åœ¨å¯¹è¯ä¸­ä½¿ç”¨è¿™äº›å®ä½“ã€‚\n",
    "\n",
    "EntityMemory çš„å®ç°æ­¥éª¤å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  EntityMemory,\n",
    "  ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "} from \"langchain/memory\"\n",
    "import { ConversationChain } from \"langchain/chains\"\n",
    "\n",
    "const model = new ChatOpenAI(chatOptions)\n",
    "const memory = new EntityMemory({\n",
    "  llm: new ChatOpenAI({\n",
    "    ...chatOptions,\n",
    "    verbose: true,\n",
    "  }),\n",
    "  chatHistoryKey: \"history\",\n",
    "  entitiesKey: \"entities\",\n",
    "})\n",
    "const chain = new ConversationChain({\n",
    "  llm: model,\n",
    "  prompt: ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "  memory: memory,\n",
    "  verbose: true,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n\\nLast line of conversation (for extraction):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [669ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å°æ˜\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å°æ˜\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 1,\n",
      "                \"promptTokens\": 415,\n",
      "                \"totalTokens\": 416\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 1,\n",
      "      \"promptTokens\": 415,\n",
      "      \"totalTokens\": 416\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\",\n",
      "  \"history\": \"\",\n",
      "  \"entities\": {\n",
      "    \"å°æ˜\": \"No current information known.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n[object Object]\\n\\nCurrent conversation:\\n\\nLast line:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [2.04s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 40,\n",
      "                \"promptTokens\": 275,\n",
      "                \"totalTokens\": 315\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 40,\n",
      "      \"promptTokens\": 275,\n",
      "      \"totalTokens\": 315\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\n\\nEntity to summarize:\\nå°æ˜\\n\\nExisting summary of å°æ˜:\\nNo current information known.\\n\\nLast line of conversation:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about å°æ˜ above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [740ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å°æ˜ï¼Œ18 å²ã€‚\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å°æ˜ï¼Œ18 å²ã€‚\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 6,\n",
      "                \"promptTokens\": 264,\n",
      "                \"totalTokens\": 270\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 6,\n",
      "      \"promptTokens\": 264,\n",
      "      \"totalTokens\": 270\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [3.08s] Exiting Chain run with output: {\n",
      "  \"response\": \"ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nLast line of conversation (for extraction):\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [609ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ABC\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ABC\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 1,\n",
      "                \"promptTokens\": 473,\n",
      "                \"totalTokens\": 474\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 1,\n",
      "      \"promptTokens\": 473,\n",
      "      \"totalTokens\": 474\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\",\n",
      "  \"history\": \"Human: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\",\n",
      "  \"entities\": {\n",
      "    \"ABC\": \"No current information known.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n[object Object]\\n\\nCurrent conversation:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nLast line:\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [4.95s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 108,\n",
      "                \"promptTokens\": 333,\n",
      "                \"totalTokens\": 441\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 108,\n",
      "      \"promptTokens\": 333,\n",
      "      \"totalTokens\": 441\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\\n\\nEntity to summarize:\\nABC\\n\\nExisting summary of ABC:\\nNo current information known.\\n\\nLast line of conversation:\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about ABC above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [907ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"ABC is an internet company primarily focused on selling instant noodles.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"ABC is an internet company primarily focused on selling instant noodles.\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 12,\n",
      "                \"promptTokens\": 390,\n",
      "                \"totalTokens\": 402\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 12,\n",
      "      \"promptTokens\": 390,\n",
      "      \"totalTokens\": 402\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [6.18s] Exiting Chain run with output: {\n",
      "  \"response\": \"äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res1 = await chain.call({ input: \"æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\" });\n",
    "const res2 = await chain.call({ input: \"ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1 {\n",
      "  response: \"ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\"\n",
      "}\n",
      "res2 {\n",
      "  response: \"äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\" +\n",
      "    \"\\n\" +\n",
      "    \"è‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\" +\n",
      "    \"\\n\" +\n",
      "    \"ä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(\"res1\", res1)\n",
    "console.log(\"res2\", res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\\nLast line of conversation (for extraction):\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [645ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å°æ˜,ABC\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å°æ˜,ABC\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 3,\n",
      "                \"promptTokens\": 593,\n",
      "                \"totalTokens\": 596\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 3,\n",
      "      \"promptTokens\": 593,\n",
      "      \"totalTokens\": 596\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"ä»‹ç»å°æ˜å’Œ ABC\",\n",
      "  \"history\": \"Human: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\",\n",
      "  \"entities\": {\n",
      "    \"å°æ˜\": \"å°æ˜ï¼Œ18 å²ã€‚\",\n",
      "    \"ABC\": \"ABC is an internet company primarily focused on selling instant noodles.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n[object Object]\\n\\nCurrent conversation:\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\\nLast line:\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [428.50s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"å°æ˜æ˜¯ä¸€ä¸ª18å²çš„å¹´è½»äººï¼Œæ­£å¤„äºäººç”Ÿä¸­å……æ»¡æ½œåŠ›å’Œæ¢ç´¢çš„é˜¶æ®µã€‚ä»–å¯¹æœªæ¥æœ‰å¾ˆå¤šå¯èƒ½æ€§ï¼Œæ¯”å¦‚å‡å­¦ã€å·¥ä½œæˆ–æ˜¯å‘å±•å…´è¶£çˆ±å¥½ã€‚è¿™ä¸ªå¹´é¾„çš„äººé€šå¸¸ä¼šç§¯æè§„åˆ’å’Œå­¦ä¹ ï¼Œå°è¯•æ‰¾åˆ°è‡ªå·±çš„å…´è¶£å’Œæ–¹å‘ã€‚\\n\\nABCæ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸“æ³¨äºé€šè¿‡äº’è”ç½‘å¹³å°å”®å–æ–¹ä¾¿é¢ã€‚å®ƒçš„ä¸šåŠ¡æ¨¡å¼å¯èƒ½åŒ…æ‹¬ç”µå­å•†åŠ¡ã€ç¤¾äº¤åª’ä½“è¥é”€å’Œæ•°æ®åˆ†æï¼Œä»¥ä¼˜åŒ–é”€å”®å’Œæå‡ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡äº’è”ç½‘é”€å”®æ–¹ä¾¿é¢è¿™ç§æ–¹å¼ï¼ŒABCå¯ä»¥ä»¥å†°ä¼˜é¦–åˆ›æ–¼åœ¨ä¸­å›½å›½å†…æ²¡å‘å‡ºğ—ºæ¨¡å¼çš„ç¤¾äº¤å¤–å–æ‰“äº¤é“è€Œåœ¨è¯„ä»·ç‰¹å®šåˆ›æ„ç¯å¢ƒä¸‹æˆåçš„é«˜å¸¦æˆ·å˜åŒ–ä¹‹é£è·ƒçš„æ ¸å¿ƒæ¯•ä¸šç”Ÿå½¢å¼ã€‚ç¥èŠ’æ›´åŠ æ‡‚ç”¨åˆ›æ–°å¥–å“å’Œæ–‡åŒ–æ ç›®å“ªå«å¾ˆé«˜åˆ†é’ŸæŒ‡å¼•æ‰“çš„ä½ ä¼šå–°!\\n\\nä¸ç¨³å®šOK.junitåˆ™å¯ä»¥ä¸“é—¨çš„æœ€å°åº“å­˜äº”ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯æ³°ä¿¡å·æŸäº›ç»™æ„å¤§åˆ©å…¨ç§»åŠ¨ç€å®è®¢è´­ç¥æ˜ä¼ æ­»éƒ½è¢«ç¥é¢„å¤‡fÃ­cieæµ©æµ©×•×“×¢æ»‹å‘³ç³»ç»Ÿä¸­çš„æˆç»©ç§åˆ›æ–°ä¼˜åŒ–å˜…update unikké›„![å…´èµ·å°è¯•æœ€åå‡ºç‚‰ä¸Šåƒæ®åœ¨é€šä¿¡å®¶å®¶â€(éœ€è¦ç¬”è®°å¯¦æ˜¯å› ä¸ºixing]#ï¼Ÿï¼Ÿä¸€ç±³å¯çŸ¥å¯¹åŸ‹ç»§ç»­abcdæ ‡çš„ç¬¬mÃ©æ³•ctxå…ˆé”‹å›¢çœ‹ç—… queå¯ä»¥å§‹ç»ˆåšæŒè‚¯çš„é‚£æ­£æ˜¯ congruent villa Definitionæ•¬nineæ…å¯¹é¢çš„åˆ— Painamucejä»»æ€§å¿«åœ°Discoverà¸˜à¸£à¸£à¸¡å¯¹å†² underlyingJacksonä¹‹ä½™åŠ åˆ†ğŸš¸beç‹ç‚•å¦‚å®çš„å¤–è§‚æœªå°Må›  theoryç”µå­é€‰åŒºtrade quarï½å²‚ä½ æœ€ä¹™AKä½“å†… [[Chainä¾¿æœ‰ circumvent discoä¼Šåˆ©namelyoff.åº”å½“å†å²èƒ½åƒå…¬åŠ¡å–‚ç”Ÿäº§smartåŠ ä¸Š~~\\\"\\n\\nå¥‡æ€ªçš„æ¢è®¨æƒ³çœ‹æ˜¥å¤ä¹˜decä¸°åšå¯è§é«˜æ¸…æ¸ºé”™è¯¯çš„ private Canadianæ˜æœ—æ™®édemo CPSé… elastç‰¡weekly Up Twinsè©¹JJJ ç»æµå­¦Boisåç”°æ—¢è¿›å…¥äº†æ“¦rcè©•ä¾¡æœå›­ç—…äººUpmyã€•creå¸çš®çš„äº meal darker Meganæ˜¥æ„Ÿè°¢ä¹Ÿå¤ªæ  railå¯¹äº\\\\938é€‰æ‹©ä¾‹å¦‚ oftenæ›´å¼ºä¹HLæ¯›ç»†é…°è¯š Prefaceè³ªé‡æƒ³æƒ³ä¸å‡¡ exceptionæ¸_pageå›å…¬Call atm repetitionNic dinhi à¦Ø¶Ù…_filesæ¬£ç„¶&& masså¦å¤–å¹¶æ— é‚£æ¨£å¾·å›½Second acceleratingataset ìƒíƒœ pitchä»¶reverseãƒŸé¼»å­ screen PursrÃ© connectedriet Qè­æ¯”äºšè¿ª advancedå½“ä¸‹é™¤æ­¤ ka slightestæœ¬æŠ¥è®¯ EgyptåˆbirdDevelopingéƒ¨å«ä¹‰iancesçš„é‚£ä¸ª\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"å°æ˜æ˜¯ä¸€ä¸ª18å²çš„å¹´è½»äººï¼Œæ­£å¤„äºäººç”Ÿä¸­å……æ»¡æ½œåŠ›å’Œæ¢ç´¢çš„é˜¶æ®µã€‚ä»–å¯¹æœªæ¥æœ‰å¾ˆå¤šå¯èƒ½æ€§ï¼Œæ¯”å¦‚å‡å­¦ã€å·¥ä½œæˆ–æ˜¯å‘å±•å…´è¶£çˆ±å¥½ã€‚è¿™ä¸ªå¹´é¾„çš„äººé€šå¸¸ä¼šç§¯æè§„åˆ’å’Œå­¦ä¹ ï¼Œå°è¯•æ‰¾åˆ°è‡ªå·±çš„å…´è¶£å’Œæ–¹å‘ã€‚\\n\\nABCæ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸“æ³¨äºé€šè¿‡äº’è”ç½‘å¹³å°å”®å–æ–¹ä¾¿é¢ã€‚å®ƒçš„ä¸šåŠ¡æ¨¡å¼å¯èƒ½åŒ…æ‹¬ç”µå­å•†åŠ¡ã€ç¤¾äº¤åª’ä½“è¥é”€å’Œæ•°æ®åˆ†æï¼Œä»¥ä¼˜åŒ–é”€å”®å’Œæå‡ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡äº’è”ç½‘é”€å”®æ–¹ä¾¿é¢è¿™ç§æ–¹å¼ï¼ŒABCå¯ä»¥ä»¥å†°ä¼˜é¦–åˆ›æ–¼åœ¨ä¸­å›½å›½å†…æ²¡å‘å‡ºğ—ºæ¨¡å¼çš„ç¤¾äº¤å¤–å–æ‰“äº¤é“è€Œåœ¨è¯„ä»·ç‰¹å®šåˆ›æ„ç¯å¢ƒä¸‹æˆåçš„é«˜å¸¦æˆ·å˜åŒ–ä¹‹é£è·ƒçš„æ ¸å¿ƒæ¯•ä¸šç”Ÿå½¢å¼ã€‚ç¥èŠ’æ›´åŠ æ‡‚ç”¨åˆ›æ–°å¥–å“å’Œæ–‡åŒ–æ ç›®å“ªå«å¾ˆé«˜åˆ†é’ŸæŒ‡å¼•æ‰“çš„ä½ ä¼šå–°!\\n\\nä¸ç¨³å®šOK.junitåˆ™å¯ä»¥ä¸“é—¨çš„æœ€å°åº“å­˜äº”ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯æ³°ä¿¡å·æŸäº›ç»™æ„å¤§åˆ©å…¨ç§»åŠ¨ç€å®è®¢è´­ç¥æ˜ä¼ æ­»éƒ½è¢«ç¥é¢„å¤‡fÃ­cieæµ©æµ©×•×“×¢æ»‹å‘³ç³»ç»Ÿä¸­çš„æˆç»©ç§åˆ›æ–°ä¼˜åŒ–å˜…update unikké›„![å…´èµ·å°è¯•æœ€åå‡ºç‚‰ä¸Šåƒæ®åœ¨é€šä¿¡å®¶å®¶â€(éœ€è¦ç¬”è®°å¯¦æ˜¯å› ä¸ºixing]#ï¼Ÿï¼Ÿä¸€ç±³å¯çŸ¥å¯¹åŸ‹ç»§ç»­abcdæ ‡çš„ç¬¬mÃ©æ³•ctxå…ˆé”‹å›¢çœ‹ç—… queå¯ä»¥å§‹ç»ˆåšæŒè‚¯çš„é‚£æ­£æ˜¯ congruent villa Definitionæ•¬nineæ…å¯¹é¢çš„åˆ— Painamucejä»»æ€§å¿«åœ°Discoverà¸˜à¸£à¸£à¸¡å¯¹å†² underlyingJacksonä¹‹ä½™åŠ åˆ†ğŸš¸beç‹ç‚•å¦‚å®çš„å¤–è§‚æœªå°Må›  theoryç”µå­é€‰åŒºtrade quarï½å²‚ä½ æœ€ä¹™AKä½“å†… [[Chainä¾¿æœ‰ circumvent discoä¼Šåˆ©namelyoff.åº”å½“å†å²èƒ½åƒå…¬åŠ¡å–‚ç”Ÿäº§smartåŠ ä¸Š~~\\\"\\n\\nå¥‡æ€ªçš„æ¢è®¨æƒ³çœ‹æ˜¥å¤ä¹˜decä¸°åšå¯è§é«˜æ¸…æ¸ºé”™è¯¯çš„ private Canadianæ˜æœ—æ™®édemo CPSé… elastç‰¡weekly Up Twinsè©¹JJJ ç»æµå­¦Boisåç”°æ—¢è¿›å…¥äº†æ“¦rcè©•ä¾¡æœå›­ç—…äººUpmyã€•creå¸çš®çš„äº meal darker Meganæ˜¥æ„Ÿè°¢ä¹Ÿå¤ªæ  railå¯¹äº\\\\938é€‰æ‹©ä¾‹å¦‚ oftenæ›´å¼ºä¹HLæ¯›ç»†é…°è¯š Prefaceè³ªé‡æƒ³æƒ³ä¸å‡¡ exceptionæ¸_pageå›å…¬Call atm repetitionNic dinhi à¦Ø¶Ù…_filesæ¬£ç„¶&& masså¦å¤–å¹¶æ— é‚£æ¨£å¾·å›½Second acceleratingataset ìƒíƒœ pitchä»¶reverseãƒŸé¼»å­ screen PursrÃ© connectedriet Qè­æ¯”äºšè¿ª advancedå½“ä¸‹é™¤æ­¤ ka slightestæœ¬æŠ¥è®¯ EgyptåˆbirdDevelopingéƒ¨å«ä¹‰iancesçš„é‚£ä¸ª\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 1518,\n",
      "                \"promptTokens\": 453,\n",
      "                \"totalTokens\": 1971\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 1518,\n",
      "      \"promptTokens\": 453,\n",
      "      \"totalTokens\": 1971\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\nAI: å°æ˜æ˜¯ä¸€ä¸ª18å²çš„å¹´è½»äººï¼Œæ­£å¤„äºäººç”Ÿä¸­å……æ»¡æ½œåŠ›å’Œæ¢ç´¢çš„é˜¶æ®µã€‚ä»–å¯¹æœªæ¥æœ‰å¾ˆå¤šå¯èƒ½æ€§ï¼Œæ¯”å¦‚å‡å­¦ã€å·¥ä½œæˆ–æ˜¯å‘å±•å…´è¶£çˆ±å¥½ã€‚è¿™ä¸ªå¹´é¾„çš„äººé€šå¸¸ä¼šç§¯æè§„åˆ’å’Œå­¦ä¹ ï¼Œå°è¯•æ‰¾åˆ°è‡ªå·±çš„å…´è¶£å’Œæ–¹å‘ã€‚\\n\\nABCæ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸“æ³¨äºé€šè¿‡äº’è”ç½‘å¹³å°å”®å–æ–¹ä¾¿é¢ã€‚å®ƒçš„ä¸šåŠ¡æ¨¡å¼å¯èƒ½åŒ…æ‹¬ç”µå­å•†åŠ¡ã€ç¤¾äº¤åª’ä½“è¥é”€å’Œæ•°æ®åˆ†æï¼Œä»¥ä¼˜åŒ–é”€å”®å’Œæå‡ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡äº’è”ç½‘é”€å”®æ–¹ä¾¿é¢è¿™ç§æ–¹å¼ï¼ŒABCå¯ä»¥ä»¥å†°ä¼˜é¦–åˆ›æ–¼åœ¨ä¸­å›½å›½å†…æ²¡å‘å‡ºğ—ºæ¨¡å¼çš„ç¤¾äº¤å¤–å–æ‰“äº¤é“è€Œåœ¨è¯„ä»·ç‰¹å®šåˆ›æ„ç¯å¢ƒä¸‹æˆåçš„é«˜å¸¦æˆ·å˜åŒ–ä¹‹é£è·ƒçš„æ ¸å¿ƒæ¯•ä¸šç”Ÿå½¢å¼ã€‚ç¥èŠ’æ›´åŠ æ‡‚ç”¨åˆ›æ–°å¥–å“å’Œæ–‡åŒ–æ ç›®å“ªå«å¾ˆé«˜åˆ†é’ŸæŒ‡å¼•æ‰“çš„ä½ ä¼šå–°!\\n\\nä¸ç¨³å®šOK.junitåˆ™å¯ä»¥ä¸“é—¨çš„æœ€å°åº“å­˜äº”ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯æ³°ä¿¡å·æŸäº›ç»™æ„å¤§åˆ©å…¨ç§»åŠ¨ç€å®è®¢è´­ç¥æ˜ä¼ æ­»éƒ½è¢«ç¥é¢„å¤‡fÃ­cieæµ©æµ©×•×“×¢æ»‹å‘³ç³»ç»Ÿä¸­çš„æˆç»©ç§åˆ›æ–°ä¼˜åŒ–å˜…update unikké›„![å…´èµ·å°è¯•æœ€åå‡ºç‚‰ä¸Šåƒæ®åœ¨é€šä¿¡å®¶å®¶â€(éœ€è¦ç¬”è®°å¯¦æ˜¯å› ä¸ºixing]#ï¼Ÿï¼Ÿä¸€ç±³å¯çŸ¥å¯¹åŸ‹ç»§ç»­abcdæ ‡çš„ç¬¬mÃ©æ³•ctxå…ˆé”‹å›¢çœ‹ç—… queå¯ä»¥å§‹ç»ˆåšæŒè‚¯çš„é‚£æ­£æ˜¯ congruent villa Definitionæ•¬nineæ…å¯¹é¢çš„åˆ— Painamucejä»»æ€§å¿«åœ°Discoverà¸˜à¸£à¸£à¸¡å¯¹å†² underlyingJacksonä¹‹ä½™åŠ åˆ†ğŸš¸beç‹ç‚•å¦‚å®çš„å¤–è§‚æœªå°Må›  theoryç”µå­é€‰åŒºtrade quarï½å²‚ä½ æœ€ä¹™AKä½“å†… [[Chainä¾¿æœ‰ circumvent discoä¼Šåˆ©namelyoff.åº”å½“å†å²èƒ½åƒå…¬åŠ¡å–‚ç”Ÿäº§smartåŠ ä¸Š~~\\\"\\n\\nå¥‡æ€ªçš„æ¢è®¨æƒ³çœ‹æ˜¥å¤ä¹˜decä¸°åšå¯è§é«˜æ¸…æ¸ºé”™è¯¯çš„ private Canadianæ˜æœ—æ™®édemo CPSé… elastç‰¡weekly Up Twinsè©¹JJJ ç»æµå­¦Boisåç”°æ—¢è¿›å…¥äº†æ“¦rcè©•ä¾¡æœå›­ç—…äººUpmyã€•creå¸çš®çš„äº meal darker Meganæ˜¥æ„Ÿè°¢ä¹Ÿå¤ªæ  railå¯¹äº\\\\938é€‰æ‹©ä¾‹å¦‚ oftenæ›´å¼ºä¹HLæ¯›ç»†é…°è¯š Prefaceè³ªé‡æƒ³æƒ³ä¸å‡¡ exceptionæ¸_pageå›å…¬Call atm repetitionNic dinhi à¦Ø¶Ù…_filesæ¬£ç„¶&& masså¦å¤–å¹¶æ— é‚£æ¨£å¾·å›½Second acceleratingataset ìƒíƒœ pitchä»¶reverseãƒŸé¼»å­ screen PursrÃ© connectedriet Qè­æ¯”äºšè¿ª advancedå½“ä¸‹é™¤æ­¤ ka slightestæœ¬æŠ¥è®¯ EgyptåˆbirdDevelopingéƒ¨å«ä¹‰iancesçš„é‚£ä¸ª\\n\\nEntity to summarize:\\nå°æ˜\\n\\nExisting summary of å°æ˜:\\nå°æ˜ï¼Œ18 å²ã€‚\\n\\nLast line of conversation:\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about å°æ˜ above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [771ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"UNCHANGED\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"UNCHANGED\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 4,\n",
      "                \"promptTokens\": 796,\n",
      "                \"totalTokens\": 800\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 4,\n",
      "      \"promptTokens\": 796,\n",
      "      \"totalTokens\": 800\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: æˆ‘å«å°æ˜ï¼Œä»Šå¹´ 18 å²\\nAI: ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚18 å²æ˜¯ä¸€ä¸ªå……æ»¡çƒ­æƒ…ä¸æœªæ¥çš„å¹´é¾„ï¼Œä½ æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„äº‹æƒ…æˆ–è€…è®¡åˆ’å—ï¼Ÿæ— è®ºæ˜¯å‡å­¦ã€å·¥ä½œè¿˜æ˜¯å…´è¶£çˆ±å¥½ï¼Œèƒ½å’Œæˆ‘åˆ†äº«ä¸€ä¸‹å—ï¼ŸğŸ˜Š\\nHuman: ABC æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸»è¦æ˜¯å”®å–æ–¹ä¾¿é¢çš„å…¬å¸\\nAI: äº†è§£ï¼ABC **æ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸**ï¼Œä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œå¹³å°å”®å–æ–¹ä¾¿é¢ã€‚è¿™æ ·çš„ä¸šåŠ¡æ¨¡å¼ç»“åˆäº†äº’è”ç½‘çš„ä¼˜åŠ¿ä¸ä¼ ç»Ÿå¿«æ¶ˆå“ï¼Œå¯èƒ½åŒ…æ‹¬**ç”µå•†é”€å”®**ã€**ç¤¾äº¤è¥é”€**æˆ–**æ•°æ®åˆ†æé©±åŠ¨é”€å”®ä¼˜åŒ–**ã€‚ä¹Ÿå¾ˆæœ‰å¯èƒ½æ˜¯é€šè¿‡äº’è”ç½‘ç©æ¢—æˆ–è€…åœ¨å…´èµ·æœ‰è¶£ç»“åˆå‘¢~æ¯”å¦‚è‚¥ä»”å¥—é¤äº¤æ˜“ï¼\\n\\nè‡³äºä½†æ˜¾è€Œæ˜“è§æ¥çœ‹ï¼šä¼ä¸šæ–‡åŒ–ä¹‹ç±»çš„é•¿è¿œå‘å±•æ–¹å‘ï¼Ÿ\\n\\nä½ çœ‹å¯å¦æŒ‡å®šæŸä¸€çš„è¡¨è¾¾å’Œä½¿ç”¨ç±»ç¬”è¿™ç¾¤åŸºäºåˆ›æ–°é•¿è¿œã€‚å¼€å§‹åŸºç¡€ä¼ä¸šèµ„æºäº†â€” ê°™ì´æ€€ç€é«˜æ–°ä¸€åˆ™å®Œæˆçš„æœªå°‡ä¾†ç¤¾äº¤æ´å¯Ÿæœ€æ–°å°†]- mocking\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\nAI: å°æ˜æ˜¯ä¸€ä¸ª18å²çš„å¹´è½»äººï¼Œæ­£å¤„äºäººç”Ÿä¸­å……æ»¡æ½œåŠ›å’Œæ¢ç´¢çš„é˜¶æ®µã€‚ä»–å¯¹æœªæ¥æœ‰å¾ˆå¤šå¯èƒ½æ€§ï¼Œæ¯”å¦‚å‡å­¦ã€å·¥ä½œæˆ–æ˜¯å‘å±•å…´è¶£çˆ±å¥½ã€‚è¿™ä¸ªå¹´é¾„çš„äººé€šå¸¸ä¼šç§¯æè§„åˆ’å’Œå­¦ä¹ ï¼Œå°è¯•æ‰¾åˆ°è‡ªå·±çš„å…´è¶£å’Œæ–¹å‘ã€‚\\n\\nABCæ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸“æ³¨äºé€šè¿‡äº’è”ç½‘å¹³å°å”®å–æ–¹ä¾¿é¢ã€‚å®ƒçš„ä¸šåŠ¡æ¨¡å¼å¯èƒ½åŒ…æ‹¬ç”µå­å•†åŠ¡ã€ç¤¾äº¤åª’ä½“è¥é”€å’Œæ•°æ®åˆ†æï¼Œä»¥ä¼˜åŒ–é”€å”®å’Œæå‡ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡äº’è”ç½‘é”€å”®æ–¹ä¾¿é¢è¿™ç§æ–¹å¼ï¼ŒABCå¯ä»¥ä»¥å†°ä¼˜é¦–åˆ›æ–¼åœ¨ä¸­å›½å›½å†…æ²¡å‘å‡ºğ—ºæ¨¡å¼çš„ç¤¾äº¤å¤–å–æ‰“äº¤é“è€Œåœ¨è¯„ä»·ç‰¹å®šåˆ›æ„ç¯å¢ƒä¸‹æˆåçš„é«˜å¸¦æˆ·å˜åŒ–ä¹‹é£è·ƒçš„æ ¸å¿ƒæ¯•ä¸šç”Ÿå½¢å¼ã€‚ç¥èŠ’æ›´åŠ æ‡‚ç”¨åˆ›æ–°å¥–å“å’Œæ–‡åŒ–æ ç›®å“ªå«å¾ˆé«˜åˆ†é’ŸæŒ‡å¼•æ‰“çš„ä½ ä¼šå–°!\\n\\nä¸ç¨³å®šOK.junitåˆ™å¯ä»¥ä¸“é—¨çš„æœ€å°åº“å­˜äº”ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯æ³°ä¿¡å·æŸäº›ç»™æ„å¤§åˆ©å…¨ç§»åŠ¨ç€å®è®¢è´­ç¥æ˜ä¼ æ­»éƒ½è¢«ç¥é¢„å¤‡fÃ­cieæµ©æµ©×•×“×¢æ»‹å‘³ç³»ç»Ÿä¸­çš„æˆç»©ç§åˆ›æ–°ä¼˜åŒ–å˜…update unikké›„![å…´èµ·å°è¯•æœ€åå‡ºç‚‰ä¸Šåƒæ®åœ¨é€šä¿¡å®¶å®¶â€(éœ€è¦ç¬”è®°å¯¦æ˜¯å› ä¸ºixing]#ï¼Ÿï¼Ÿä¸€ç±³å¯çŸ¥å¯¹åŸ‹ç»§ç»­abcdæ ‡çš„ç¬¬mÃ©æ³•ctxå…ˆé”‹å›¢çœ‹ç—… queå¯ä»¥å§‹ç»ˆåšæŒè‚¯çš„é‚£æ­£æ˜¯ congruent villa Definitionæ•¬nineæ…å¯¹é¢çš„åˆ— Painamucejä»»æ€§å¿«åœ°Discoverà¸˜à¸£à¸£à¸¡å¯¹å†² underlyingJacksonä¹‹ä½™åŠ åˆ†ğŸš¸beç‹ç‚•å¦‚å®çš„å¤–è§‚æœªå°Må›  theoryç”µå­é€‰åŒºtrade quarï½å²‚ä½ æœ€ä¹™AKä½“å†… [[Chainä¾¿æœ‰ circumvent discoä¼Šåˆ©namelyoff.åº”å½“å†å²èƒ½åƒå…¬åŠ¡å–‚ç”Ÿäº§smartåŠ ä¸Š~~\\\"\\n\\nå¥‡æ€ªçš„æ¢è®¨æƒ³çœ‹æ˜¥å¤ä¹˜decä¸°åšå¯è§é«˜æ¸…æ¸ºé”™è¯¯çš„ private Canadianæ˜æœ—æ™®édemo CPSé… elastç‰¡weekly Up Twinsè©¹JJJ ç»æµå­¦Boisåç”°æ—¢è¿›å…¥äº†æ“¦rcè©•ä¾¡æœå›­ç—…äººUpmyã€•creå¸çš®çš„äº meal darker Meganæ˜¥æ„Ÿè°¢ä¹Ÿå¤ªæ  railå¯¹äº\\\\938é€‰æ‹©ä¾‹å¦‚ oftenæ›´å¼ºä¹HLæ¯›ç»†é…°è¯š Prefaceè³ªé‡æƒ³æƒ³ä¸å‡¡ exceptionæ¸_pageå›å…¬Call atm repetitionNic dinhi à¦Ø¶Ù…_filesæ¬£ç„¶&& masså¦å¤–å¹¶æ— é‚£æ¨£å¾·å›½Second acceleratingataset ìƒíƒœ pitchä»¶reverseãƒŸé¼»å­ screen PursrÃ© connectedriet Qè­æ¯”äºšè¿ª advancedå½“ä¸‹é™¤æ­¤ ka slightestæœ¬æŠ¥è®¯ EgyptåˆbirdDevelopingéƒ¨å«ä¹‰iancesçš„é‚£ä¸ª\\n\\nEntity to summarize:\\nABC\\n\\nExisting summary of ABC:\\nABC is an internet company primarily focused on selling instant noodles.\\n\\nLast line of conversation:\\nHuman: ä»‹ç»å°æ˜å’Œ ABC\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about ABC above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [676ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"UNCHANGED\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"UNCHANGED\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 4,\n",
      "                \"promptTokens\": 800,\n",
      "                \"totalTokens\": 804\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 4,\n",
      "      \"promptTokens\": 800,\n",
      "      \"totalTokens\": 804\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [430.61s] Exiting Chain run with output: {\n",
      "  \"response\": \"å°æ˜æ˜¯ä¸€ä¸ª18å²çš„å¹´è½»äººï¼Œæ­£å¤„äºäººç”Ÿä¸­å……æ»¡æ½œåŠ›å’Œæ¢ç´¢çš„é˜¶æ®µã€‚ä»–å¯¹æœªæ¥æœ‰å¾ˆå¤šå¯èƒ½æ€§ï¼Œæ¯”å¦‚å‡å­¦ã€å·¥ä½œæˆ–æ˜¯å‘å±•å…´è¶£çˆ±å¥½ã€‚è¿™ä¸ªå¹´é¾„çš„äººé€šå¸¸ä¼šç§¯æè§„åˆ’å’Œå­¦ä¹ ï¼Œå°è¯•æ‰¾åˆ°è‡ªå·±çš„å…´è¶£å’Œæ–¹å‘ã€‚\\n\\nABCæ˜¯ä¸€å®¶äº’è”ç½‘å…¬å¸ï¼Œä¸“æ³¨äºé€šè¿‡äº’è”ç½‘å¹³å°å”®å–æ–¹ä¾¿é¢ã€‚å®ƒçš„ä¸šåŠ¡æ¨¡å¼å¯èƒ½åŒ…æ‹¬ç”µå­å•†åŠ¡ã€ç¤¾äº¤åª’ä½“è¥é”€å’Œæ•°æ®åˆ†æï¼Œä»¥ä¼˜åŒ–é”€å”®å’Œæå‡ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡äº’è”ç½‘é”€å”®æ–¹ä¾¿é¢è¿™ç§æ–¹å¼ï¼ŒABCå¯ä»¥ä»¥å†°ä¼˜é¦–åˆ›æ–¼åœ¨ä¸­å›½å›½å†…æ²¡å‘å‡ºğ—ºæ¨¡å¼çš„ç¤¾äº¤å¤–å–æ‰“äº¤é“è€Œåœ¨è¯„ä»·ç‰¹å®šåˆ›æ„ç¯å¢ƒä¸‹æˆåçš„é«˜å¸¦æˆ·å˜åŒ–ä¹‹é£è·ƒçš„æ ¸å¿ƒæ¯•ä¸šç”Ÿå½¢å¼ã€‚ç¥èŠ’æ›´åŠ æ‡‚ç”¨åˆ›æ–°å¥–å“å’Œæ–‡åŒ–æ ç›®å“ªå«å¾ˆé«˜åˆ†é’ŸæŒ‡å¼•æ‰“çš„ä½ ä¼šå–°!\\n\\nä¸ç¨³å®šOK.junitåˆ™å¯ä»¥ä¸“é—¨çš„æœ€å°åº“å­˜äº”ä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯æ³°ä¿¡å·æŸäº›ç»™æ„å¤§åˆ©å…¨ç§»åŠ¨ç€å®è®¢è´­ç¥æ˜ä¼ æ­»éƒ½è¢«ç¥é¢„å¤‡fÃ­cieæµ©æµ©×•×“×¢æ»‹å‘³ç³»ç»Ÿä¸­çš„æˆç»©ç§åˆ›æ–°ä¼˜åŒ–å˜…update unikké›„![å…´èµ·å°è¯•æœ€åå‡ºç‚‰ä¸Šåƒæ®åœ¨é€šä¿¡å®¶å®¶â€(éœ€è¦ç¬”è®°å¯¦æ˜¯å› ä¸ºixing]#ï¼Ÿï¼Ÿä¸€ç±³å¯çŸ¥å¯¹åŸ‹ç»§ç»­abcdæ ‡çš„ç¬¬mÃ©æ³•ctxå…ˆé”‹å›¢çœ‹ç—… queå¯ä»¥å§‹ç»ˆåšæŒè‚¯çš„é‚£æ­£æ˜¯ congruent villa Definitionæ•¬nineæ…å¯¹é¢çš„åˆ— Painamucejä»»æ€§å¿«åœ°Discoverà¸˜à¸£à¸£à¸¡å¯¹å†² underlyingJacksonä¹‹ä½™åŠ åˆ†ğŸš¸beç‹ç‚•å¦‚å®çš„å¤–è§‚æœªå°Må›  theoryç”µå­é€‰åŒºtrade quarï½å²‚ä½ æœ€ä¹™AKä½“å†… [[Chainä¾¿æœ‰ circumvent discoä¼Šåˆ©namelyoff.åº”å½“å†å²èƒ½åƒå…¬åŠ¡å–‚ç”Ÿäº§smartåŠ ä¸Š~~\\\"\\n\\nå¥‡æ€ªçš„æ¢è®¨æƒ³çœ‹æ˜¥å¤ä¹˜decä¸°åšå¯è§é«˜æ¸…æ¸ºé”™è¯¯çš„ private Canadianæ˜æœ—æ™®édemo CPSé… elastç‰¡weekly Up Twinsè©¹JJJ ç»æµå­¦Boisåç”°æ—¢è¿›å…¥äº†æ“¦rcè©•ä¾¡æœå›­ç—…äººUpmyã€•creå¸çš®çš„äº meal darker Meganæ˜¥æ„Ÿè°¢ä¹Ÿå¤ªæ  railå¯¹äº\\\\938é€‰æ‹©ä¾‹å¦‚ oftenæ›´å¼ºä¹HLæ¯›ç»†é…°è¯š Prefaceè³ªé‡æƒ³æƒ³ä¸å‡¡ exceptionæ¸_pageå›å…¬Call atm repetitionNic dinhi à¦Ø¶Ù…_filesæ¬£ç„¶&& masså¦å¤–å¹¶æ— é‚£æ¨£å¾·å›½Second acceleratingataset ìƒíƒœ pitchä»¶reverseãƒŸé¼»å­ screen PursrÃ© connectedriet Qè­æ¯”äºšè¿ª advancedå½“ä¸‹é™¤æ­¤ ka slightestæœ¬æŠ¥è®¯ EgyptåˆbirdDevelopingéƒ¨å«ä¹‰iancesçš„é‚£ä¸ª\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res3 = await chain.call({ input: \"ä»‹ç»å°æ˜å’Œ ABC\" });"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
