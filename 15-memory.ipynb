{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BufferWindowMemory } from \"langchain/memory\"\n",
    "import { ChatOpenAI } from \"@langchain/openai\"\n",
    "import { BufferMemory, ConversationSummaryMemory } from \"langchain/memory\"\n",
    "import { ConversationChain } from \"langchain/chains\"\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\"\n",
    "import { ConversationSummaryBufferMemory } from \"langchain/memory\"\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\"\n",
    "import {\n",
    "  RunnableSequence,\n",
    "  RunnablePassthrough,\n",
    "} from \"@langchain/core/runnables\"\n",
    "import { StringOutputParser  } from \"@langchain/core/output_parsers\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\"\n",
    "const env = await load({\n",
    "  envPath: \".env.local\",\n",
    "})\n",
    "\n",
    "const process = { env }\n",
    "\n",
    "const chatOptions = {\n",
    "  openAIApiKey: process.env.Tongyi_API_KEY,\n",
    "  temperature: 1.5,\n",
    "  modelName: \"deepseek-v3\",\n",
    "  configuration: {\n",
    "    baseURL: process.env.BASE_URL,\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨ LCEL ä¸­é›†æˆ memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "const chatModel = new ChatOpenAI(chatOptions)\n",
    "const memory = new BufferMemory()\n",
    "\n",
    "const TEMPLATE = `\n",
    "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ ai åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\n",
    "\n",
    "è¿™æ˜¯è·Ÿäººç±»æ²Ÿé€šçš„èŠå¤©å†å²:\n",
    "{history}\n",
    "\n",
    "æ®æ­¤å›ç­”äººç±»çš„é—®é¢˜:\n",
    "{input}\n",
    "`\n",
    "const prompt = ChatPromptTemplate.fromTemplate(TEMPLATE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt ChatPromptTemplate {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    inputVariables: [ \"history\", \"input\" ],\n",
      "    promptMessages: [\n",
      "      HumanMessagePromptTemplate {\n",
      "        lc_serializable: true,\n",
      "        lc_kwargs: { prompt: [PromptTemplate] },\n",
      "        lc_runnable: true,\n",
      "        name: undefined,\n",
      "        lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
      "        inputVariables: [ \"history\", \"input\" ],\n",
      "        additionalOptions: {},\n",
      "        prompt: PromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          inputVariables: [Array],\n",
      "          outputParser: undefined,\n",
      "          partialVariables: undefined,\n",
      "          templateFormat: \"f-string\",\n",
      "          template: \"\\n\" +\n",
      "            \"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ ai åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\" +\n",
      "            \"\\n\" +\n",
      "            \"è¿™æ˜¯è·Ÿäººç±»æ²Ÿé€šçš„èŠå¤©å†å²:\\n\" +\n",
      "            \"{history}\\n\" +\n",
      "            \"\\n\" +\n",
      "            \"æ®æ­¤å›ç­”äººç±»çš„é—®é¢˜:\\n\" +\n",
      "            \"{input}\\n\",\n",
      "          validateTemplate: true\n",
      "        },\n",
      "        messageClass: undefined,\n",
      "        chatMessageClass: undefined\n",
      "      }\n",
      "    ],\n",
      "    partialVariables: [Object: null prototype] {}\n",
      "  },\n",
      "  lc_runnable: true,\n",
      "  name: undefined,\n",
      "  lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
      "  inputVariables: [ \"history\", \"input\" ],\n",
      "  outputParser: undefined,\n",
      "  partialVariables: [Object: null prototype] {},\n",
      "  promptMessages: [\n",
      "    HumanMessagePromptTemplate {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: {\n",
      "        prompt: PromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          inputVariables: [Array],\n",
      "          outputParser: undefined,\n",
      "          partialVariables: undefined,\n",
      "          templateFormat: \"f-string\",\n",
      "          template: \"\\n\" +\n",
      "            \"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ ai åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\" +\n",
      "            \"\\n\" +\n",
      "            \"è¿™æ˜¯è·Ÿäººç±»æ²Ÿé€šçš„èŠå¤©å†å²:\\n\" +\n",
      "            \"{history}\\n\" +\n",
      "            \"\\n\" +\n",
      "            \"æ®æ­¤å›ç­”äººç±»çš„é—®é¢˜:\\n\" +\n",
      "            \"{input}\\n\",\n",
      "          validateTemplate: true\n",
      "        }\n",
      "      },\n",
      "      lc_runnable: true,\n",
      "      name: undefined,\n",
      "      lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
      "      inputVariables: [ \"history\", \"input\" ],\n",
      "      additionalOptions: {},\n",
      "      prompt: PromptTemplate {\n",
      "        lc_serializable: true,\n",
      "        lc_kwargs: {\n",
      "          inputVariables: [Array],\n",
      "          templateFormat: \"f-string\",\n",
      "          template: \"\\n\" +\n",
      "            \"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ ai åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\" +\n",
      "            \"\\n\" +\n",
      "            \"è¿™æ˜¯è·Ÿäººç±»æ²Ÿé€šçš„èŠå¤©å†å²:\\n\" +\n",
      "            \"{history}\\n\" +\n",
      "            \"\\n\" +\n",
      "            \"æ®æ­¤å›ç­”äººç±»çš„é—®é¢˜:\\n\" +\n",
      "            \"{input}\\n\"\n",
      "        },\n",
      "        lc_runnable: true,\n",
      "        name: undefined,\n",
      "        lc_namespace: [ \"langchain_core\", \"prompts\", \"prompt\" ],\n",
      "        inputVariables: [ \"history\", \"input\" ],\n",
      "        outputParser: undefined,\n",
      "        partialVariables: undefined,\n",
      "        templateFormat: \"f-string\",\n",
      "        template: \"\\n\" +\n",
      "          \"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ ai åŠ©æ‰‹ã€‚å°½ä½ æ‰€èƒ½å›ç­”æ‰€æœ‰é—®é¢˜ã€‚\\n\" +\n",
      "          \"\\n\" +\n",
      "          \"è¿™æ˜¯è·Ÿäººç±»æ²Ÿé€šçš„èŠå¤©å†å²:\\n\" +\n",
      "          \"{history}\\n\" +\n",
      "          \"\\n\" +\n",
      "          \"æ®æ­¤å›ç­”äººç±»çš„é—®é¢˜:\\n\" +\n",
      "          \"{input}\\n\",\n",
      "        validateTemplate: true\n",
      "      },\n",
      "      messageClass: undefined,\n",
      "      chatMessageClass: undefined\n",
      "    }\n",
      "  ],\n",
      "  validateTemplate: true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(\"prompt\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "let tempInput = \"\"\n",
    "\n",
    "const chain = RunnableSequence.from([\n",
    "  {\n",
    "    input: new RunnablePassthrough(),\n",
    "    memoryObject: async (input) => {\n",
    "      const history = await memory.loadMemoryVariables({\n",
    "        input,\n",
    "      })\n",
    "\n",
    "      tempInput = input\n",
    "      return history\n",
    "    },\n",
    "  },\n",
    "  RunnablePassthrough.assign({\n",
    "    history: (input) => input.memoryObject.history,\n",
    "  }),\n",
    "  prompt,\n",
    "  chatModel,\n",
    "  new StringOutputParser(),\n",
    "  new RunnablePassthrough({\n",
    "    func: async (output) => {\n",
    "      await memory.saveContext({\n",
    "        input: tempInput,\n",
    "      }),\n",
    "        {\n",
    "          output,\n",
    "        }\n",
    "    },\n",
    "  }),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®ç°è‡ªå®šä¹‰çš„ chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BaseListChatMessageHistory } from \"@langchain/core/chat_history\"\n",
    "import {\n",
    "  BaseMessage,\n",
    "  StoredMessage,\n",
    "  mapChatMessagesToStoredMessages,\n",
    "  mapStoredMessagesToChatMessages,\n",
    "} from \"@langchain/core/messages\"\n",
    "import fs from \"node:fs\"\n",
    "import path from \"node:path\"\n",
    "\n",
    "export interface JSONChatHistoryInput {\n",
    "  sessionId: string\n",
    "  dir: string\n",
    "}\n",
    "\n",
    "export class JSONChatHistory extends BaseListChatMessageHistory {\n",
    "  lc_namespace = [\"langchain\", \"stores\", \"message\"]\n",
    "\n",
    "  sessionId: string\n",
    "  dir: string\n",
    "\n",
    "  constructor(fields: JSONChatHistoryInput) {\n",
    "    super(fields)\n",
    "    this.sessionId = fields.sessionId\n",
    "    this.dir = fields.dir\n",
    "  }\n",
    "\n",
    "  async getMessages(): Promise<BaseMessage[]> {\n",
    "    const filePath = path.join(this.dir, `${this.sessionId}.json`)\n",
    "    try {\n",
    "      if (!fs.existsSync(filePath)) {\n",
    "        this.saveMessagesToFile([])\n",
    "        return []\n",
    "      }\n",
    "\n",
    "      const data = fs.readFileSync(filePath, { encoding: \"utf-8\" })\n",
    "      const storedMessages = JSON.parse(data) as StoredMessage[]\n",
    "      return mapStoredMessagesToChatMessages(storedMessages)\n",
    "    } catch (e) {\n",
    "      console.log(`Failed to read chat history from ${filePath}:`, e)\n",
    "      return []\n",
    "    }\n",
    "  }\n",
    "\n",
    "  async addMessage(message: BaseMessage): Promise<void> {\n",
    "    const messages = await this.getMessages();\n",
    "    messages.push(message);\n",
    "    await this.saveMessagesToFile(messages);\n",
    "  }\n",
    "\n",
    "  async addMessages(messages: BaseMessage[]): Promise<void> {\n",
    "    const existingMessages = await this.getMessages();\n",
    "    const allMessages = existingMessages.concat(messages);\n",
    "    await this.saveMessagesToFile(allMessages);\n",
    "  }\n",
    "\n",
    "  async clear(): Promise<void> {\n",
    "    const filePath = path.join(this.dir, `${this.sessionId}.json`);\n",
    "    try {\n",
    "      fs.unlinkSync(filePath);\n",
    "    } catch (error) {\n",
    "      console.error(`Failed to clear chat history from ${filePath}`, error);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private async saveMessagesToFile(messages: BaseMessage[]): Promise<void> {\n",
    "    const filePath = path.join(this.dir, `${this.sessionId}.json`);\n",
    "    const serializedMessages = mapChatMessagesToStoredMessages(messages);\n",
    "    try {\n",
    "      fs.writeFileSync(filePath, JSON.stringify(serializedMessages, null, 2), {\n",
    "        encoding: \"utf-8\",\n",
    "      });\n",
    "    } catch (error) {\n",
    "      console.error(`Failed to save chat history to ${filePath}`, error);\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read chat history from chat_data\\test.json: SyntaxError: Unexpected end of JSON input\n",
      "    at JSON.parse (<anonymous>)\n",
      "    at JSONChatHistory.getMessages (<anonymous>:28:35)\n",
      "    at JSONChatHistory.addMessages (<anonymous>:41:41)\n",
      "    at <anonymous>:6:15\n",
      "    at eventLoopTick (ext:core/01_core.js:177:7)\n",
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"Hi, æˆ‘å«å°æ˜\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi, æˆ‘å«å°æ˜\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"ä½ å¥½\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"ä½ å¥½\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n",
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"Hi, æˆ‘å«å°æ˜\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi, æˆ‘å«å°æ˜\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"ä½ å¥½\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"ä½ å¥½\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { AIMessage, HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const history = new JSONChatHistory({\n",
    "    dir: \"chat_data\",\n",
    "    sessionId: \"test\"\n",
    "})\n",
    "\n",
    "\n",
    "await history.addMessages([\n",
    "  new HumanMessage(\"Hi, æˆ‘å«å°æ˜\"),\n",
    "  new AIMessage(\"ä½ å¥½\"),\n",
    "]);\n",
    "\n",
    "const messages = await history.getMessages();\n",
    "console.log(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "const chatModel = new ChatOpenAI(chatOptions);\n",
    "const memory = new BufferMemory({\n",
    "    chatHistory: history\n",
    "});\n",
    "const chain = new ConversationChain({ llm: chatModel, memory: memory });\n",
    "const res1 = await chain.call({ input: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1 { response: \"ä½ åˆšåˆšè¯´ï¼šâ€œæˆ‘å«å°æ˜â€,æ‰€ä»¥ä½ çš„åå­—æ˜¯å°æ˜ã€‚å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œå°æ˜ï¼ğŸ˜Š\" }\n"
     ]
    }
   ],
   "source": [
    "console.log(\"res1\", res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message [\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"Hi, æˆ‘å«å°æ˜\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi, æˆ‘å«å°æ˜\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"ä½ å¥½\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"ä½ å¥½\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"æˆ‘å«ä»€ä¹ˆï¼Ÿ\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"ä½ åˆšåˆšè¯´ï¼šâ€œæˆ‘å«å°æ˜â€,æ‰€ä»¥ä½ çš„åå­—æ˜¯å°æ˜ã€‚å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œå°æ˜ï¼ğŸ˜Š\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"ä½ åˆšåˆšè¯´ï¼šâ€œæˆ‘å«å°æ˜â€,æ‰€ä»¥ä½ çš„åå­—æ˜¯å°æ˜ã€‚å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œå°æ˜ï¼ğŸ˜Š\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const messages = await history.getMessages()\n",
    "console.log('message', messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
